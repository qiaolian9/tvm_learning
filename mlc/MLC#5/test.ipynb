{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import relax\n",
    "from tvm.script import relax as R\n",
    "from tvm.script import tir as T\n",
    "from tvm.ir import IRModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.fx as fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.rand((64, 10)))\n",
    "        self.bias = nn.Parameter(torch.rand((10, )))\n",
    "        self.linear1 = nn.Linear(10, 3, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv = nn.Conv2d(1, 1, 3, 1, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.relu(x)\n",
    "        x = x.view((1, -1))\n",
    "        x = torch.matmul(x, self.weight)\n",
    "        x = torch.add(x, self.bias)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear1(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_mod = MyModule()\n",
    "hw = 10\n",
    "data = np.random.rand(1, 1, hw, hw).astype('float32')\n",
    "\n",
    "torch_out = torch_mod(torch.from_numpy(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm import te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def te_matmul(x: te.Tensor, w: te.Tensor):\n",
    "    n = x.shape[0]\n",
    "    m = w.shape[1]\n",
    "    k = te.reduce_axis((0, x.shape[1]), 'k')\n",
    "    return te.compute((n, m), lambda i, j: te.sum(x[i, k] * w[k, j], axis=k), name='matmul')\n",
    "\n",
    "def te_add(x: te.Tensor, b: te.Tensor):\n",
    "    n, m = x.shape\n",
    "    return te.compute(x.shape, lambda i, j: x[i, j] + b[j], name='add')\n",
    "\n",
    "def te_relu(x: te.Tensor):\n",
    "    return te.compute(x.shape, lambda *i: te.max(x(*i), 0), name='relu')\n",
    "\n",
    "def te_view(x: te.Tensor):\n",
    "    n, c, h, w = x.shape\n",
    "    m = np.prod(x.shape) // n\n",
    "    return te.compute((n, m), lambda i, j: x[i, j // (h * w), j % (h * w) // w, j % (h * w) % w], name='view')\n",
    "\n",
    "def te_conv2d(x: te.Tensor, kernel: te.Tensor):\n",
    "    n, ci, h, w = x.shape\n",
    "    _, co, k1, k2 = kernel.shape\n",
    "    h_1, w_1 = h - k1 + 1, w - k2 + 1\n",
    "    ci = te.reduce_axis((0, ci), name='ci')\n",
    "    k1 = te.reduce_axis((0, k1), name='k1')\n",
    "    k2 = te.reduce_axis((0, k2), name='k2')\n",
    "    return te.compute((n, co, h_1, w_1), lambda i, j, k, l:\n",
    "                            te.sum(x[i, ci, k+k1, l+k2] * kernel[j, ci, k1, k2], axis=[ci, k1, k2]), name='conv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = te.placeholder((1,1,10,10), dtype='float32')\n",
    "# K = te.placeholder((1, 1, 3, 3), dtype='float32')\n",
    "# C = te_conv2d(A, K)\n",
    "# print(C.shape)\n",
    "# te.create_prim_func([A, K, C]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name     target                                                     args             kwargs\n",
      "-------------  -------  ---------------------------------------------------------  ---------------  --------\n",
      "placeholder    x        x                                                          ()               {}\n",
      "call_module    conv     conv                                                       (x,)             {}\n",
      "call_function  relu     <built-in method relu of type object at 0x7f8d3b810ec0>    (conv,)          {}\n",
      "call_method    view     view                                                       (relu, (1, -1))  {}\n",
      "get_attr       weight   weight                                                     ()               {}\n",
      "call_function  matmul   <built-in method matmul of type object at 0x7f8d3b810ec0>  (view, weight)   {}\n",
      "get_attr       bias     bias                                                       ()               {}\n",
      "call_function  add      <built-in method add of type object at 0x7f8d3b810ec0>     (matmul, bias)   {}\n",
      "call_module    relu_1   relu                                                       (add,)           {}\n",
      "call_module    linear1  linear1                                                    (relu_1,)        {}\n",
      "output         output   output                                                     (linear1,)       {}\n"
     ]
    }
   ],
   "source": [
    "# create computation graph\n",
    "fx_module = fx.symbolic_trace(torch_mod)\n",
    "fx_module.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x <class 'torch.fx.node.Node'> <class 'str'>\n",
      "conv <class 'torch.fx.node.Node'> <class 'str'>\n",
      "relu <class 'torch.fx.node.Node'> <class 'builtin_function_or_method'>\n",
      "view <class 'torch.fx.node.Node'> <class 'str'>\n",
      "weight <class 'torch.fx.node.Node'> <class 'str'>\n",
      "matmul <class 'torch.fx.node.Node'> <class 'builtin_function_or_method'>\n",
      "bias <class 'torch.fx.node.Node'> <class 'str'>\n",
      "add <class 'torch.fx.node.Node'> <class 'builtin_function_or_method'>\n",
      "relu_1 <class 'torch.fx.node.Node'> <class 'str'>\n",
      "linear1 <class 'torch.fx.node.Node'> <class 'str'>\n",
      "output <class 'torch.fx.node.Node'> <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for node in fx_module.graph.nodes:\n",
    "    print(node, type(node), type(node.target))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "with bb.function('main):\n",
    "    with bb.dataflow():\n",
    "        y = bb.emit_te(func_name, input_)\n",
    "        ...\n",
    "        with bb.emit_output(out)\n",
    "    with bb.emit_func_output(out, fn_inputs)\n",
    "\n",
    "MyModule = bb.get() # ---> IRModule\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造映射函数\n",
    "def map_params(param: nn.Parameter):\n",
    "    return relax.const(param.data.cpu().numpy(), dtype='float32')\n",
    "\n",
    "def fetch_attr(fx_mod, target: str):\n",
    "    target_atoms = target.split('.')\n",
    "    attr_itr = fx_mod\n",
    "    for i, atom in enumerate(target_atoms):\n",
    "        if not hasattr(attr_itr, atom):\n",
    "            raise RuntimeError(f\"Node referenced nonexistant target {'.'.join(target_atoms[:i])}\")\n",
    "        attr_itr = getattr(attr_itr, atom)\n",
    "    return attr_itr\n",
    "\n",
    "def from_fx(fx_module, input_shapes, call_function_map, call_module_map, call_method_map):\n",
    "    fn_inputs = []\n",
    "    fn_output = None\n",
    "    input_index = 0\n",
    "\n",
    "    node_map = {}\n",
    "    named_modules = dict(fx_module.named_modules())\n",
    "\n",
    "    bb = relax.BlockBuilder()\n",
    "\n",
    "    with bb.function('main'):\n",
    "        with bb.dataflow():\n",
    "            for node in fx_module.graph.nodes:\n",
    "                if node.op == \"placeholder\":\n",
    "                    shape = input_shapes[input_index]\n",
    "                    input_index = input_index + 1\n",
    "                    fn_input = relax.Var(node.target, R.Tensor(shape=shape, dtype='float32'))\n",
    "                    fn_inputs.append(fn_input)\n",
    "                    node_map[node] = fn_input\n",
    "                elif node.op == \"get_attr\":\n",
    "                    node_map[node] = map_params(fetch_attr(fx_module, node.target))\n",
    "                elif node.op == \"call_function\":\n",
    "                    node_map[node] = call_function_map[node.target](bb, node_map, node)\n",
    "                elif node.op == \"call_module\":\n",
    "                    named_module = named_modules[node.target]\n",
    "                    node_map[node] = call_module_map[type(named_module)](bb, node_map, node, named_module)\n",
    "                elif node.op == \"call_method\":\n",
    "                    node_map[node] = call_method_map[node.target](bb, node_map, node)\n",
    "                elif node.op == \"output\":\n",
    "                    output = node_map[node.args[0]]\n",
    "                    assert fn_output is None\n",
    "                    fn_output = bb.emit_output(output)\n",
    "        bb.emit_func_output(fn_output, fn_inputs)\n",
    "    return bb.get()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_function\n",
    "def map_matmul(bb, node_map, node):\n",
    "    x = node_map[node.args[0]]\n",
    "    w = node_map[node.args[1]]\n",
    "    return bb.emit_te(te_matmul, x, w)\n",
    "\n",
    "def map_relu(bb, node_map, node):\n",
    "    x = node_map[node.args[0]]\n",
    "    return bb.emit_te(te_relu, x)\n",
    "\n",
    "def map_add(bb, node_map, node):\n",
    "    x = node_map[node.args[0]]\n",
    "    b = node_map[node.args[1]]\n",
    "    return bb.emit_te(te_add, x, b)\n",
    "\n",
    "# call_module\n",
    "from tvm import topi\n",
    "def map_nn_conv(bb, node_map, node, nn_mod):\n",
    "    x = node_map[node.args[0]]\n",
    "    kernel = map_params(nn_mod.weight)\n",
    "    return bb.emit_te(te_conv2d, x, kernel)\n",
    "\n",
    "def map_nn_linear(bb, node_map, node, nn_mod):\n",
    "    x = node_map[node.args[0]]\n",
    "    w = map_params(nn_mod.weight)\n",
    "    b = None\n",
    "    if nn_mod.bias is not None:\n",
    "        b = map_params(nn_mod.bias)\n",
    "    return bb.emit_te(topi.nn.dense, x, w, b)\n",
    "    \n",
    "def map_nn_relu(bb, node_map, node, nn_mod):\n",
    "    x = node_map[node.args[0]]\n",
    "    return bb.emit_te(topi.nn.relu, x)\n",
    "\n",
    "# call method\n",
    "def map_view(bb, node_map, node):\n",
    "    x = node_map[node.args[0]]\n",
    "    return bb.emit_te(te_view, x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyDemo = from_fx(fx_module=fx_module, input_shapes=[(1, 1, hw, hw),],\n",
    "                    call_function_map={\n",
    "                        torch.matmul: map_matmul,\n",
    "                        torch.add: map_add,\n",
    "                        torch.relu: map_relu\n",
    "                    },\n",
    "                    call_module_map={\n",
    "                        torch.nn.ReLU: map_nn_relu,\n",
    "                        torch.nn.Conv2d: map_nn_conv,\n",
    "                        torch.nn.Linear: map_nn_linear\n",
    "                    },\n",
    "                    call_method_map={'view': map_view})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/staff/qiaoliang/anaconda3/envs/MLC/lib/python3.8/site-packages/tvm/script/highlight.py:116: UserWarning: No module named 'black'\n",
      "To print formatted TVM script, please install the formatter 'Black':\n",
      "/staff/qiaoliang/anaconda3/envs/MLC/bin/python -m pip install \"black==22.3.0\" --upgrade --user\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #AA22FF\">@tvm</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>script<span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">te_view</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">8</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">8</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], view: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;view&quot;</span>):\n",
       "                v_i, v_j <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i, j])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_i, v_j <span style=\"color: #AA22FF; font-weight: bold\">//</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>), v_j <span style=\"color: #AA22FF; font-weight: bold\">%</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>) <span style=\"color: #AA22FF; font-weight: bold\">//</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">8</span>), v_j <span style=\"color: #AA22FF; font-weight: bold\">%</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">8</span>)])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(view[v_i, v_j])\n",
       "                view[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> rxplaceholder[v_i, v_j <span style=\"color: #AA22FF; font-weight: bold\">//</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>), v_j <span style=\"color: #AA22FF; font-weight: bold\">%</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>) <span style=\"color: #AA22FF; font-weight: bold\">//</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">8</span>), v_j <span style=\"color: #AA22FF; font-weight: bold\">%</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">8</span>)]\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">te_add</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], add: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;add&quot;</span>):\n",
       "                v_i, v_j <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i, j])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_i, v_j], rxplaceholder_1[v_j])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(add[v_i, v_j])\n",
       "                add[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> rxplaceholder[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder_1[v_j]\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">te_matmul</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], matmul: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;matmul&quot;</span>):\n",
       "                v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_i, v_k], rxplaceholder_1[v_k, v_j])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(matmul[v_i, v_j])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> rxplaceholder_1[v_k, v_j]\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">dense</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], rxplaceholder_2: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], compute: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;layout_free_buffers&quot;</span>: [<span style=\"color: #008000\">1</span>], <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        T_matmul_NT <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer([T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>)], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NT&quot;</span>):\n",
       "                v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_i, v_k], rxplaceholder_1[v_j, v_k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NT[v_i, v_j])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    T_matmul_NT[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                T_matmul_NT[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NT[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> rxplaceholder_1[v_j, v_k]\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;compute&quot;</span>):\n",
       "                v_i, v_j <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i, j])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(T_matmul_NT[v_i, v_j], rxplaceholder_2[v_j])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(compute[v_i, v_j])\n",
       "                compute[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NT[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder_2[v_j]\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">relu</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], compute: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;compute&quot;</span>):\n",
       "                v_i0, v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_i0, v_i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(compute[v_i0, v_i1])\n",
       "                compute[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(rxplaceholder[v_i0, v_i1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">te_relu</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">8</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">8</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">8</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">8</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2, i3 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">8</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">8</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
       "                v_i0, v_i1, v_i2, v_i3 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSS&quot;</span>, [i0, i1, i2, i3])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_i0, v_i1, v_i2, v_i3])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[v_i0, v_i1, v_i2, v_i3])\n",
       "                relu[v_i0, v_i1, v_i2, v_i3] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(rxplaceholder[v_i0, v_i1, v_i2, v_i3], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        <span style=\"color: #007979; font-style: italic\"># block 0</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(te_conv2d, (x, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(te_relu, (lv,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(te_view, (lv1,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv3 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(te_matmul, (lv2, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">1</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv4 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(te_add, (lv3, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">2</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv5 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(relu, (lv4,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv6 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(dense, (lv5, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">3</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">4</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv6\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "        \n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">te_conv2d</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], conv: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">8</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">8</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k, l, ci, k1, k2 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">8</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">8</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;conv&quot;</span>):\n",
       "                v_i, v_j, v_k, v_l, v_ci, v_k1, v_k2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSSRRR&quot;</span>, [i, j, k, l, ci, k1, k2])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_i, v_ci, v_k <span style=\"color: #AA22FF; font-weight: bold\">+</span> v_k1, v_l <span style=\"color: #AA22FF; font-weight: bold\">+</span> v_k2], rxplaceholder_1[v_j, v_ci, v_k1, v_k2])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(conv[v_i, v_j, v_k, v_l])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    conv[v_i, v_j, v_k, v_l] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                conv[v_i, v_j, v_k, v_l] <span style=\"color: #AA22FF; font-weight: bold\">=</span> conv[v_i, v_j, v_k, v_l] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder[v_i, v_ci, v_k <span style=\"color: #AA22FF; font-weight: bold\">+</span> v_k1, v_l <span style=\"color: #AA22FF; font-weight: bold\">+</span> v_k2] <span style=\"color: #AA22FF; font-weight: bold\">*</span> rxplaceholder_1[v_j, v_ci, v_k1, v_k2]\n",
       "    \n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MyDemo.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = relax.vm.build(MyDemo, target='llvm')\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu())\n",
    "\n",
    "tvm_out = vm['main'](tvm.nd.array(data))\n",
    "np.testing.assert_allclose(tvm_out.numpy(), torch_out.detach().cpu().numpy(), rtol=1e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df7b789d6764113f3eb4ff8e192e7912fbf893c46539f75332048503ce5ba603"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
