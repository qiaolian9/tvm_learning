{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 端到端模型执行\n",
    "## 3.1 前言\n",
    "什么是可能的张量函数抽象表达形式？\\\n",
    "什么是可能的张量函数变换？"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import IPython\n",
    "import tvm\n",
    "import numpy as np\n",
    "from tvm.script import tir as T\n",
    "from tvm.script import  relax as R\n",
    "from tvm.ir.module import IRModule\n",
    "from tvm import relax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "import torch\n",
    "import torchvision\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "img, label = next(iter(test_loader))\n",
    "img = img.reshape(1, 28, 28).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "print(\"Class:\", class_names[label[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt\n",
    "# Hide outputs\n",
    "# !wget https://github.com/mlc-ai/web-data/raw/main/models/fasionmnist_mlp_params.pkl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 端到端模型整合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear -> relu -> Linear\n",
    "# numpy version\n",
    "def numpy_mlp(data, w0, b0, w1, b1):\n",
    "    # print(data.shape, w0.shape)\n",
    "    lv0 = data @ w0.T + b0\n",
    "    lv1 = np.maximum(lv0, 0)\n",
    "    lv2 = lv1 @ w1.T + b1\n",
    "    return lv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-28.304363   -35.1353     -20.574154   -20.60154    -17.119598\n",
      "    2.7829077  -15.253116     0.21253912  -4.941823     8.811271  ]]\n",
      "[9]\n",
      "numpy mlp prediction: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "mlp_params = pkl.load(open(\"/staff/qiaoliang/ACSA科研项目/tvm_learning/mlc/fasionmnist_mlp_params.pkl\", \"rb\"))\n",
    "\n",
    "res = numpy_mlp(img.reshape(1, 784),\n",
    "                mlp_params[\"w0\"],\n",
    "                mlp_params[\"b0\"],\n",
    "                mlp_params[\"w1\"],\n",
    "                mlp_params[\"b1\"])\n",
    "\n",
    "print(res)\n",
    "pred_kind = res.argmax(axis=1)\n",
    "print(pred_kind)\n",
    "print(\"numpy mlp prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level Numpy MLP Prediction: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "# low level numpy version\n",
    "def lnumpy_linear0(X: np.ndarray, W: np.ndarray, B: np.ndarray, Z: np.ndarray):\n",
    "    Y = np.empty((1, 128), 'float32')\n",
    "    for i in range(1):\n",
    "        for j in range(128):\n",
    "            for k in range(784):\n",
    "                if k == 0 :\n",
    "                    Y[i, j] = 0\n",
    "                Y[i, j] = Y[i, j] + X[i, k] * W[j, k]\n",
    "    \n",
    "    for i in range(1):\n",
    "        for j in range(128):\n",
    "            Z[i, j] = Y[i, j] + B[j]\n",
    "\n",
    "def lnumpy_relu(X: np.ndarray, Z: np.ndarray):\n",
    "    for i in range(1):\n",
    "        for j in range(128):\n",
    "            Z[i, j] = np.maximum(X[i, j], 0)\n",
    "\n",
    "def lnumpy_linear1(X: np.ndarray, W: np.ndarray, B: np.ndarray, Z: np.ndarray):\n",
    "    Y =  np.empty((1, 10), dtype='float32')\n",
    "    for i in range(1):\n",
    "        for j in range(10):\n",
    "            for k in range(128):\n",
    "                if k == 0:\n",
    "                    Y[i, j] = 0\n",
    "                Y[i, j] = Y[i, j] + X[i, k] * W[j, k]\n",
    "    \n",
    "    for i in range(1):\n",
    "        for j in range(10):\n",
    "            Z[i, j] = Y[i, j] + B[j]\n",
    "\n",
    "def lnumpy_mlp(X: np.ndarray,\n",
    "               W0: np.ndarray,\n",
    "               B0: np.ndarray,\n",
    "               W1: np.ndarray,\n",
    "               B1: np.ndarray):\n",
    "    lv1 = np.empty((1, 128), dtype='float32')\n",
    "    lv2 = np.empty((1, 128), dtype='float32')\n",
    "    out = np.empty((1, 10), dtype='float32')\n",
    "    lnumpy_linear0(X, W0, B0, lv1)\n",
    "    lnumpy_relu(lv1, lv2)\n",
    "    lnumpy_linear1(lv2, W1, B1, out)\n",
    "    return out\n",
    "\n",
    "res_lnumpy = lnumpy_mlp(img.reshape(1, 784), \n",
    "                        mlp_params[\"w0\"],\n",
    "                        mlp_params[\"b0\"],\n",
    "                        mlp_params[\"w1\"],\n",
    "                        mlp_params[\"b1\"])\n",
    "\n",
    "pred_kind_lnumpy = res_lnumpy.argmax(axis=1)\n",
    "print(\"Low-level Numpy MLP Prediction:\", class_names[pred_kind_lnumpy[0]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 TVMScript中构建IRModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorIR\n",
    "# Method 1: IRModule ----> tvm.build ----> rt_lib\n",
    "@tvm.script.ir_module\n",
    "class MyModule():\n",
    "    @T.prim_func\n",
    "    def relu(X: T.Buffer[(1, 128), 'float32'],\n",
    "             Z: T.Buffer[(1, 128), 'float32']):\n",
    "        T.func_attr({\"global_symbol\": \"relu\", \"tir.noalias\": True})\n",
    "        for i, j in T.grid(1, 128):\n",
    "            with T.block('Z'):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                Z[vi, vj] = T.max(X[i, j], T.float32(0))\n",
    "    \n",
    "    @T.prim_func\n",
    "    def linear0(X: T.Buffer[(1, 784), 'float32'],\n",
    "                W: T.Buffer[(128, 784), 'float32'],\n",
    "                B: T.Buffer[(128), 'float32'],\n",
    "                Z: T.Buffer[(1, 128), 'float32']):\n",
    "        T.func_attr({\"global_symbol\": \"linear0\", \"tir.noalias\": True})\n",
    "        Y = T.alloc_buffer((1, 128), dtype='float32')\n",
    "        for i, j, k in T.grid(1, 128, 784):\n",
    "            with T.block(\"Y\"):\n",
    "                vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
    "                with T.init():\n",
    "                    Y[vi, vj] = T.float32(0)\n",
    "                Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk]\n",
    "        \n",
    "        for i, j in T.grid(1, 128):\n",
    "            with T.block(\"Z\"):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                Z[vi, vj] = Y[vi, vj] + B[vj]\n",
    "    \n",
    "    @T.prim_func\n",
    "    def linear1(X: T.Buffer[(1, 128), 'float32'],\n",
    "                W: T.Buffer[(10, 128), 'float32'],\n",
    "                B: T.Buffer[(10), 'float32'],\n",
    "                Z: T.Buffer[(1, 10), 'float32']):\n",
    "        T.func_attr({\"global_symbol\": \"linear1\", \"tir.noalias\": True})\n",
    "        Y = T.alloc_buffer((1, 10), dtype='float32')\n",
    "        for i, j, k in T.grid(1, 10, 128):\n",
    "            with T.block(\"Y\"):\n",
    "                vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
    "                with T.init():\n",
    "                    Y[vi, vj] = T.float32(0)\n",
    "                Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk]\n",
    "        \n",
    "        for i, j in T.grid(1, 10):\n",
    "            with T.block(\"Z\"):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                Z[vi, vj] = Y[vi, vj] + B[vj]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorIR MLP Prediction: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "rt_lib = tvm.build(MyModule, target='llvm')\n",
    "func_0 = rt_lib['linear0']\n",
    "func_1 = rt_lib['relu']\n",
    "func_2 = rt_lib['linear1']\n",
    "\n",
    "lv1 = tvm.nd.empty((1, 128), dtype='float32')\n",
    "lv2 = tvm.nd.empty((1, 128), dtype='float32')\n",
    "res_tvm = tvm.nd.empty((1, 10), dtype='float32')\n",
    "func_0(tvm.nd.array(img.reshape(1, 784)), tvm.nd.array(mlp_params[\"w0\"]), tvm.nd.array(mlp_params[\"b0\"]), lv1)\n",
    "func_1(lv1, lv2)\n",
    "func_2(lv2, tvm.nd.array(mlp_params[\"w1\"]), tvm.nd.array(mlp_params[\"b1\"]), res_tvm)\n",
    "\n",
    "pred_kind_tvm = res_tvm.numpy().argmax(axis=1)\n",
    "print(\"TensorIR MLP Prediction:\", class_names[pred_kind_tvm[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyModule:\n",
    "    @T.prim_func\n",
    "    def relu0(X: T.Buffer[(1, 128), \"float32\"],\n",
    "              Y: T.Buffer[(1, 128), \"float32\"]):\n",
    "        # function attr dict\n",
    "        T.func_attr({\"global_symbol\": \"relu0\", \"tir.noalias\": True})\n",
    "        for i, j in T.grid(1, 128):\n",
    "            with T.block(\"Y\"):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                Y[vi, vj] = T.max(X[vi, vj], T.float32(0))\n",
    "\n",
    "    @T.prim_func\n",
    "    def linear0(X: T.Buffer[(1, 784), \"float32\"],\n",
    "                W: T.Buffer[(128, 784), \"float32\"],\n",
    "                B: T.Buffer[(128,), \"float32\"],\n",
    "                Z: T.Buffer[(1, 128), \"float32\"]):\n",
    "        T.func_attr({\"global_symbol\": \"linear0\", \"tir.noalias\": True})\n",
    "        Y = T.alloc_buffer((1, 128), \"float32\")\n",
    "        for i, j, k in T.grid(1, 128, 784):\n",
    "            with T.block(\"Y\"):\n",
    "                vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
    "                with T.init():\n",
    "                    Y[vi, vj] = T.float32(0)\n",
    "                Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk]\n",
    "\n",
    "        for i, j in T.grid(1, 128):\n",
    "            with T.block(\"Z\"):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                Z[vi, vj] =  Y[vi, vj] + B[vj]\n",
    "\n",
    "    @T.prim_func\n",
    "    def linear1(X: T.Buffer[(1, 128), \"float32\"],\n",
    "                W: T.Buffer[(10, 128), \"float32\"],\n",
    "                B: T.Buffer[(10,), \"float32\"],\n",
    "                Z: T.Buffer[(1, 10), \"float32\"]):\n",
    "        T.func_attr({\"global_symbol\": \"linear1\", \"tir.noalias\": True})\n",
    "        Y = T.alloc_buffer((1, 10), \"float32\")\n",
    "        for i, j, k in T.grid(1, 10, 128):\n",
    "            with T.block(\"Y\"):\n",
    "                vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
    "                with T.init():\n",
    "                    Y[vi, vj] = T.float32(0)\n",
    "                Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk]\n",
    "\n",
    "        for i, j in T.grid(1, 10):\n",
    "            with T.block(\"Z\"):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                Z[vi, vj] = Y[vi, vj] + B[vj]\n",
    "\n",
    "    @R.function\n",
    "    def main(x: R.Tensor((1, 784), \"float32\"),\n",
    "             w0: R.Tensor((128, 784), \"float32\"),\n",
    "             b0: R.Tensor((128,), \"float32\"),\n",
    "             w1: R.Tensor((10, 128), \"float32\"),\n",
    "             b1: R.Tensor((10,), \"float32\")):\n",
    "        with R.dataflow():\n",
    "            lv0 = R.call_tir(linear0, (x, w0, b0), relax.TensorStructInfo((1, 128), dtype=\"float32\"))\n",
    "            lv1 = R.call_tir(relu0, (lv0,), relax.TensorStructInfo((1, 128), dtype=\"float32\"))\n",
    "            out = R.call_tir(linear1, (lv1, w1, b1), relax.TensorStructInfo((1, 10), dtype=\"float32\"))\n",
    "            R.output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relax.expr.Function(0x56125e65b6d0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyModule['main']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 call_tir\n",
    "```python\n",
    "lv0 = R.call_tir(linear0, (X, W0, B0), (1, 128))\n",
    "```\n",
    "```python\n",
    "def lnumpy_call_tir(prim_func, inputs, shape):\n",
    "    res = np.empty(shape)\n",
    "    prim_func(*input, res)\n",
    "    return res\n",
    "```\n",
    "\n",
    "call_tir 接受一个元函数 (prim_func) 的输入列表，并分配一个输出张量res，然后将输入和输出传递给prim_func。 执行 prim_func 后，结果会填充到 res 中，然后我们可以返回结果。\\\n",
    "\n",
    "**为什么我们需要 call_tir？** 这是因为我们的元张量函数采用以下调用约定：**目标传递** -> 输入和输出在外部显式分配并传递给底层元函数\n",
    "```python\n",
    "def low_level_prim_func(in0, in1, ..., out):\n",
    "    # to Do\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level Numpy with CallTIR Prediction: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "def lnumpy_call_tir(prim_func, inputs, shape, dtype):\n",
    "    res = np.empty(shape, dtype=dtype)\n",
    "    prim_func(*inputs, res)\n",
    "    return res\n",
    "    \n",
    "def lnumpy_mlp_with_call_tir(X: np.ndarray, W0: np.ndarray, B0: np.ndarray, W1: np.ndarray, B1: np.ndarray):\n",
    "    lv0 = lnumpy_call_tir(lnumpy_linear0, (X, W0, B0), (1, 128), 'float32')\n",
    "    lv1 = lnumpy_call_tir(lnumpy_relu, (lv0,), (1, 128), 'float32')\n",
    "    res = lnumpy_call_tir(lnumpy_linear1, (lv1, W1, B1), (1, 10), 'float32')\n",
    "    return res\n",
    "\n",
    "res = lnumpy_mlp_with_call_tir(img.reshape(1, 784),\n",
    "                      mlp_params['w0'],\n",
    "                      mlp_params['b0'],\n",
    "                      mlp_params['w1'],\n",
    "                      mlp_params['b1'])\n",
    "\n",
    "pred_kind_lnumpy_with_call_tir = res.argmax(axis=1)\n",
    "print(\"Low-level Numpy with CallTIR Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 Dataflow Block\n",
    "\n",
    "**回看**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 构建并运行模型\n",
    "\n",
    "```python\n",
    "IRModule --> @T.prim_func & @R.function\n",
    "1. @T.prim_func: tvm.build(IRModule) ---> rt_lib(tvm.driver.build_module.OperatorModule) ---> rt_lib[\"prim_func\"](tvm.runtime.packed_func.PackedFunc)\n",
    "2. @R.function: relax.vm.build(IRModule) ---> ex(tvm.relax.vm.Executable) ---> relax.VirtualMachine(ex, tvm.cpu()) \n",
    "        ---> vm(tvm.relax.vm.VirtualMachine) & vm['function'](tvm.runtime.packed_func.PackedFunc)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"nd\">@tvm</span><span class=\"o\">.</span><span class=\"n\">script</span><span class=\"o\">.</span><span class=\"n\">ir_module</span>\n",
       "<span class=\"k\">class</span> <span class=\"nc\">Module</span><span class=\"p\">:</span>\n",
       "    <span class=\"nd\">@R</span><span class=\"o\">.</span><span class=\"n\">function</span>\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">main</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">784</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">w0</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">784</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">b0</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">128</span><span class=\"p\">,),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">w1</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">b1</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">10</span><span class=\"p\">,),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span> <span class=\"o\">-&gt;</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">):</span>\n",
       "        <span class=\"c1\"># block 0</span>\n",
       "        <span class=\"k\">with</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">dataflow</span><span class=\"p\">():</span>\n",
       "            <span class=\"n\">lv0</span> <span class=\"o\">=</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">call_tir</span><span class=\"p\">(</span><span class=\"n\">linear0</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">w0</span><span class=\"p\">,</span> <span class=\"n\">b0</span><span class=\"p\">),</span> <span class=\"n\">out_sinfo</span><span class=\"o\">=</span><span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span>\n",
       "            <span class=\"n\">lv1</span> <span class=\"o\">=</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">call_tir</span><span class=\"p\">(</span><span class=\"n\">relu0</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">lv0</span><span class=\"p\">,),</span> <span class=\"n\">out_sinfo</span><span class=\"o\">=</span><span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span>\n",
       "            <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">call_tir</span><span class=\"p\">(</span><span class=\"n\">linear1</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">lv1</span><span class=\"p\">,</span> <span class=\"n\">w1</span><span class=\"p\">,</span> <span class=\"n\">b1</span><span class=\"p\">),</span> <span class=\"n\">out_sinfo</span><span class=\"o\">=</span><span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span>\n",
       "            <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">output</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">return</span> <span class=\"n\">out</span>\n",
       "        \n",
       "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">relu0</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">Y</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">]):</span>\n",
       "        <span class=\"c1\"># function attr dict</span>\n",
       "        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">func_attr</span><span class=\"p\">({</span><span class=\"s2\">&quot;tir.noalias&quot;</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"s2\">&quot;global_symbol&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;relu0&quot;</span><span class=\"p\">})</span>\n",
       "        <span class=\"c1\"># body</span>\n",
       "        <span class=\"c1\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Y&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">))</span>\n",
       "    \n",
       "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">linear0</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">784</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">W</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">784</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">Z</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">]):</span>\n",
       "        <span class=\"c1\"># function attr dict</span>\n",
       "        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">func_attr</span><span class=\"p\">({</span><span class=\"s2\">&quot;tir.noalias&quot;</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"s2\">&quot;global_symbol&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;linear0&quot;</span><span class=\"p\">})</span>\n",
       "        <span class=\"c1\"># body</span>\n",
       "        <span class=\"c1\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">alloc_buffer</span><span class=\"p\">([</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"n\">k</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">784</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Y&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">,</span> <span class=\"n\">vk</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SSR&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">],</span> <span class=\"n\">W</span><span class=\"p\">[</span><span class=\"n\">vj</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">init</span><span class=\"p\">():</span>\n",
       "                    <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n",
       "                <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">W</span><span class=\"p\">[</span><span class=\"n\">vj</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">]</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Z&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Z</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">Z</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vj</span><span class=\"p\">]</span>\n",
       "    \n",
       "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">linear1</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">W</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">Z</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">]):</span>\n",
       "        <span class=\"c1\"># function attr dict</span>\n",
       "        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">func_attr</span><span class=\"p\">({</span><span class=\"s2\">&quot;tir.noalias&quot;</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"s2\">&quot;global_symbol&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;linear1&quot;</span><span class=\"p\">})</span>\n",
       "        <span class=\"c1\"># body</span>\n",
       "        <span class=\"c1\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">alloc_buffer</span><span class=\"p\">([</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"n\">k</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Y&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">,</span> <span class=\"n\">vk</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SSR&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">],</span> <span class=\"n\">W</span><span class=\"p\">[</span><span class=\"n\">vj</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">init</span><span class=\"p\">():</span>\n",
       "                    <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n",
       "                <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">W</span><span class=\"p\">[</span><span class=\"n\">vj</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">]</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Z&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Z</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">Z</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vj</span><span class=\"p\">]</span>\n",
       "    \n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{n+nd}{@tvm}\\PY{o}{.}\\PY{n}{script}\\PY{o}{.}\\PY{n}{ir\\PYZus{}module}\n",
       "\\PY{k}{class} \\PY{n+nc}{Module}\\PY{p}{:}\n",
       "    \\PY{n+nd}{@R}\\PY{o}{.}\\PY{n}{function}\n",
       "    \\PY{k}{def} \\PY{n+nf}{main}\\PY{p}{(}\\PY{n}{x}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{784}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{w0}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{784}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{b0}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{w1}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{b1}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} block 0}\n",
       "        \\PY{k}{with} \\PY{n}{R}\\PY{o}{.}\\PY{n}{dataflow}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{n}{lv0} \\PY{o}{=} \\PY{n}{R}\\PY{o}{.}\\PY{n}{call\\PYZus{}tir}\\PY{p}{(}\\PY{n}{linear0}\\PY{p}{,} \\PY{p}{(}\\PY{n}{x}\\PY{p}{,} \\PY{n}{w0}\\PY{p}{,} \\PY{n}{b0}\\PY{p}{)}\\PY{p}{,} \\PY{n}{out\\PYZus{}sinfo}\\PY{o}{=}\\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
       "            \\PY{n}{lv1} \\PY{o}{=} \\PY{n}{R}\\PY{o}{.}\\PY{n}{call\\PYZus{}tir}\\PY{p}{(}\\PY{n}{relu0}\\PY{p}{,} \\PY{p}{(}\\PY{n}{lv0}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{out\\PYZus{}sinfo}\\PY{o}{=}\\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
       "            \\PY{n}{out} \\PY{o}{=} \\PY{n}{R}\\PY{o}{.}\\PY{n}{call\\PYZus{}tir}\\PY{p}{(}\\PY{n}{linear1}\\PY{p}{,} \\PY{p}{(}\\PY{n}{lv1}\\PY{p}{,} \\PY{n}{w1}\\PY{p}{,} \\PY{n}{b1}\\PY{p}{)}\\PY{p}{,} \\PY{n}{out\\PYZus{}sinfo}\\PY{o}{=}\\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
       "            \\PY{n}{R}\\PY{o}{.}\\PY{n}{output}\\PY{p}{(}\\PY{n}{out}\\PY{p}{)}\n",
       "        \\PY{k}{return} \\PY{n}{out}\n",
       "        \n",
       "    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n",
       "    \\PY{k}{def} \\PY{n+nf}{relu0}\\PY{p}{(}\\PY{n}{X}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{Y}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} function attr dict}\n",
       "        \\PY{n}{T}\\PY{o}{.}\\PY{n}{func\\PYZus{}attr}\\PY{p}{(}\\PY{p}{\\PYZob{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{tir.noalias}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{k+kc}{True}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{global\\PYZus{}symbol}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{relu0}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{\\PYZcb{}}\\PY{p}{)}\n",
       "        \\PY{c+c1}{\\PYZsh{} body}\n",
       "        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{})}\n",
       "        \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Y}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{X}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{max}\\PY{p}{(}\\PY{n}{X}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\\PY{p}{)}\n",
       "    \n",
       "    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n",
       "    \\PY{k}{def} \\PY{n+nf}{linear0}\\PY{p}{(}\\PY{n}{X}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{784}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{W}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{784}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{Z}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} function attr dict}\n",
       "        \\PY{n}{T}\\PY{o}{.}\\PY{n}{func\\PYZus{}attr}\\PY{p}{(}\\PY{p}{\\PYZob{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{tir.noalias}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{k+kc}{True}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{global\\PYZus{}symbol}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{linear0}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{\\PYZcb{}}\\PY{p}{)}\n",
       "        \\PY{c+c1}{\\PYZsh{} body}\n",
       "        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{})}\n",
       "        \\PY{n}{Y} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{alloc\\PYZus{}buffer}\\PY{p}{(}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{]}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "        \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{,} \\PY{n}{k} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{784}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Y}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{,} \\PY{n}{vk} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SSR}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{,} \\PY{n}{k}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{X}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]}\\PY{p}{,} \\PY{n}{W}\\PY{p}{[}\\PY{n}{vj}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{init}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "                    \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\n",
       "                \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{X}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]} \\PY{o}{*} \\PY{n}{W}\\PY{p}{[}\\PY{n}{vj}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]}\n",
       "        \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Z}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Z}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{Z}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vj}\\PY{p}{]}\n",
       "    \n",
       "    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n",
       "    \\PY{k}{def} \\PY{n+nf}{linear1}\\PY{p}{(}\\PY{n}{X}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{W}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{Z}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} function attr dict}\n",
       "        \\PY{n}{T}\\PY{o}{.}\\PY{n}{func\\PYZus{}attr}\\PY{p}{(}\\PY{p}{\\PYZob{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{tir.noalias}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{k+kc}{True}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{global\\PYZus{}symbol}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{linear1}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{\\PYZcb{}}\\PY{p}{)}\n",
       "        \\PY{c+c1}{\\PYZsh{} body}\n",
       "        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{})}\n",
       "        \\PY{n}{Y} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{alloc\\PYZus{}buffer}\\PY{p}{(}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{]}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "        \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{,} \\PY{n}{k} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Y}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{,} \\PY{n}{vk} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SSR}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{,} \\PY{n}{k}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{X}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]}\\PY{p}{,} \\PY{n}{W}\\PY{p}{[}\\PY{n}{vj}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{init}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "                    \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\n",
       "                \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{X}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]} \\PY{o}{*} \\PY{n}{W}\\PY{p}{[}\\PY{n}{vj}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]}\n",
       "        \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Z}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Z}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{Z}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vj}\\PY{p}{]}\n",
       "    \n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "@tvm.script.ir_module\n",
       "class Module:\n",
       "    @R.function\n",
       "    def main(x: R.Tensor((1, 784), dtype=\"float32\"), w0: R.Tensor((128, 784), dtype=\"float32\"), b0: R.Tensor((128,), dtype=\"float32\"), w1: R.Tensor((10, 128), dtype=\"float32\"), b1: R.Tensor((10,), dtype=\"float32\")) -> R.Tensor((1, 10), dtype=\"float32\"):\n",
       "        # block 0\n",
       "        with R.dataflow():\n",
       "            lv0 = R.call_tir(linear0, (x, w0, b0), out_sinfo=R.Tensor((1, 128), dtype=\"float32\"))\n",
       "            lv1 = R.call_tir(relu0, (lv0,), out_sinfo=R.Tensor((1, 128), dtype=\"float32\"))\n",
       "            out = R.call_tir(linear1, (lv1, w1, b1), out_sinfo=R.Tensor((1, 10), dtype=\"float32\"))\n",
       "            R.output(out)\n",
       "        return out\n",
       "        \n",
       "    @T.prim_func\n",
       "    def relu0(X: T.Buffer[(1, 128), \"float32\"], Y: T.Buffer[(1, 128), \"float32\"]):\n",
       "        # function attr dict\n",
       "        T.func_attr({\"tir.noalias\": True, \"global_symbol\": \"relu0\"})\n",
       "        # body\n",
       "        # with T.block(\"root\")\n",
       "        for i, j in T.grid(1, 128):\n",
       "            with T.block(\"Y\"):\n",
       "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
       "                T.reads(X[vi, vj])\n",
       "                T.writes(Y[vi, vj])\n",
       "                Y[vi, vj] = T.max(X[vi, vj], T.float32(0))\n",
       "    \n",
       "    @T.prim_func\n",
       "    def linear0(X: T.Buffer[(1, 784), \"float32\"], W: T.Buffer[(128, 784), \"float32\"], B: T.Buffer[128, \"float32\"], Z: T.Buffer[(1, 128), \"float32\"]):\n",
       "        # function attr dict\n",
       "        T.func_attr({\"tir.noalias\": True, \"global_symbol\": \"linear0\"})\n",
       "        # body\n",
       "        # with T.block(\"root\")\n",
       "        Y = T.alloc_buffer([1, 128], dtype=\"float32\")\n",
       "        for i, j, k in T.grid(1, 128, 784):\n",
       "            with T.block(\"Y\"):\n",
       "                vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
       "                T.reads(X[vi, vk], W[vj, vk])\n",
       "                T.writes(Y[vi, vj])\n",
       "                with T.init():\n",
       "                    Y[vi, vj] = T.float32(0)\n",
       "                Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk]\n",
       "        for i, j in T.grid(1, 128):\n",
       "            with T.block(\"Z\"):\n",
       "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
       "                T.reads(Y[vi, vj], B[vj])\n",
       "                T.writes(Z[vi, vj])\n",
       "                Z[vi, vj] = Y[vi, vj] + B[vj]\n",
       "    \n",
       "    @T.prim_func\n",
       "    def linear1(X: T.Buffer[(1, 128), \"float32\"], W: T.Buffer[(10, 128), \"float32\"], B: T.Buffer[10, \"float32\"], Z: T.Buffer[(1, 10), \"float32\"]):\n",
       "        # function attr dict\n",
       "        T.func_attr({\"tir.noalias\": True, \"global_symbol\": \"linear1\"})\n",
       "        # body\n",
       "        # with T.block(\"root\")\n",
       "        Y = T.alloc_buffer([1, 10], dtype=\"float32\")\n",
       "        for i, j, k in T.grid(1, 10, 128):\n",
       "            with T.block(\"Y\"):\n",
       "                vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
       "                T.reads(X[vi, vk], W[vj, vk])\n",
       "                T.writes(Y[vi, vj])\n",
       "                with T.init():\n",
       "                    Y[vi, vj] = T.float32(0)\n",
       "                Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk]\n",
       "        for i, j in T.grid(1, 10):\n",
       "            with T.block(\"Z\"):\n",
       "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
       "                T.reads(Y[vi, vj], B[vj])\n",
       "                T.writes(Z[vi, vj])\n",
       "                Z[vi, vj] = Y[vi, vj] + B[vj]\n",
       "    "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.Code(MyModule.script(), language='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tvm.relax.vm.Executable,\n",
       " tvm.driver.build_module.OperatorModule,\n",
       " tvm.runtime.packed_func.PackedFunc,\n",
       " tvm.runtime.packed_func.PackedFunc)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = relax.vm.build(MyModule, target=\"llvm\")\n",
    "# build 函数会给我们一个可执行文件（译者注：“可执行文件”并非传统操作系统中的可执行文件，不能直接在系统中运行，\\\n",
    "# 而是针对Relax VM设计的一种文件格式）。 我们可以初始化一个虚拟机执行器，使我们能够运行该函数。 此外，我们将传入第二个参数，指示我们要在哪个设备上运行端到端执行。\n",
    "type(ex), type(rt_lib), type(func_0), type(rt_lib['linear0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm = relax.VirtualMachine(ex, tvm.cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nd = tvm.nd.array(img.reshape(1, 784))\n",
    "nd_params = {k: tvm.nd.array(v) for k, v in mlp_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-28.304369   -35.135296   -20.574156   -20.601543   -17.1196\n",
      "    2.7829108  -15.253119     0.21254028  -4.941827     8.81127   ]]\n"
     ]
    }
   ],
   "source": [
    "nd_res = vm[\"main\"](data_nd,\n",
    "                    nd_params[\"w0\"],\n",
    "                    nd_params[\"b0\"],\n",
    "                    nd_params[\"w1\"],\n",
    "                    nd_params[\"b1\"])\n",
    "print(nd_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModule Prediction: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "pred_kind = np.argmax(nd_res.numpy(), axis=1)\n",
    "print(\"MyModule Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 在环境中集成现有运行库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyModuleWithExternCall:\n",
    "    @R.function\n",
    "    def main(x: R.Tensor((1, 784), \"float32\"),\n",
    "             w0: R.Tensor((128, 784), \"float32\"),\n",
    "             b0: R.Tensor((128,), \"float32\"),\n",
    "             w1: R.Tensor((10, 128), \"float32\"),\n",
    "             b1: R.Tensor((10,), \"float32\")):\n",
    "        # block 0\n",
    "        with R.dataflow():\n",
    "            lv0 = R.call_tir(\"env.linear\", (x, w0, b0), relax.TensorStructInfo((1, 128), dtype=\"float32\"))\n",
    "            lv1 = R.call_tir(\"env.relu\", (lv0,), relax.TensorStructInfo((1, 128), dtype=\"float32\"))\n",
    "            out = R.call_tir(\"env.linear\", (lv1, w1, b1), relax.TensorStructInfo((1, 10), dtype=\"float32\"))\n",
    "            R.output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"nd\">@R</span><span class=\"o\">.</span><span class=\"n\">function</span>\n",
       "<span class=\"k\">def</span> <span class=\"nf\">main</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">784</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">w0</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">784</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">b0</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">128</span><span class=\"p\">,),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">w1</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">b1</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">10</span><span class=\"p\">,),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span> <span class=\"o\">-&gt;</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">):</span>\n",
       "    <span class=\"c1\"># block 0</span>\n",
       "    <span class=\"k\">with</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">dataflow</span><span class=\"p\">():</span>\n",
       "        <span class=\"n\">lv0</span> <span class=\"o\">=</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">call_tir</span><span class=\"p\">(</span><span class=\"s2\">&quot;env.linear&quot;</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">w0</span><span class=\"p\">,</span> <span class=\"n\">b0</span><span class=\"p\">),</span> <span class=\"n\">out_sinfo</span><span class=\"o\">=</span><span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span>\n",
       "        <span class=\"n\">lv1</span> <span class=\"o\">=</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">call_tir</span><span class=\"p\">(</span><span class=\"s2\">&quot;env.relu&quot;</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">lv0</span><span class=\"p\">,),</span> <span class=\"n\">out_sinfo</span><span class=\"o\">=</span><span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span>\n",
       "        <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">call_tir</span><span class=\"p\">(</span><span class=\"s2\">&quot;env.linear&quot;</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">lv1</span><span class=\"p\">,</span> <span class=\"n\">w1</span><span class=\"p\">,</span> <span class=\"n\">b1</span><span class=\"p\">),</span> <span class=\"n\">out_sinfo</span><span class=\"o\">=</span><span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span>\n",
       "        <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">output</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">)</span>\n",
       "    <span class=\"k\">return</span> <span class=\"n\">out</span>\n",
       "    \n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{n+nd}{@R}\\PY{o}{.}\\PY{n}{function}\n",
       "\\PY{k}{def} \\PY{n+nf}{main}\\PY{p}{(}\\PY{n}{x}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{784}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{w0}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{784}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{b0}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{w1}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{b1}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "    \\PY{c+c1}{\\PYZsh{} block 0}\n",
       "    \\PY{k}{with} \\PY{n}{R}\\PY{o}{.}\\PY{n}{dataflow}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{lv0} \\PY{o}{=} \\PY{n}{R}\\PY{o}{.}\\PY{n}{call\\PYZus{}tir}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{env.linear}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{(}\\PY{n}{x}\\PY{p}{,} \\PY{n}{w0}\\PY{p}{,} \\PY{n}{b0}\\PY{p}{)}\\PY{p}{,} \\PY{n}{out\\PYZus{}sinfo}\\PY{o}{=}\\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
       "        \\PY{n}{lv1} \\PY{o}{=} \\PY{n}{R}\\PY{o}{.}\\PY{n}{call\\PYZus{}tir}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{env.relu}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{(}\\PY{n}{lv0}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{out\\PYZus{}sinfo}\\PY{o}{=}\\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
       "        \\PY{n}{out} \\PY{o}{=} \\PY{n}{R}\\PY{o}{.}\\PY{n}{call\\PYZus{}tir}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{env.linear}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{(}\\PY{n}{lv1}\\PY{p}{,} \\PY{n}{w1}\\PY{p}{,} \\PY{n}{b1}\\PY{p}{)}\\PY{p}{,} \\PY{n}{out\\PYZus{}sinfo}\\PY{o}{=}\\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
       "        \\PY{n}{R}\\PY{o}{.}\\PY{n}{output}\\PY{p}{(}\\PY{n}{out}\\PY{p}{)}\n",
       "    \\PY{k}{return} \\PY{n}{out}\n",
       "    \n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "@R.function\n",
       "def main(x: R.Tensor((1, 784), dtype=\"float32\"), w0: R.Tensor((128, 784), dtype=\"float32\"), b0: R.Tensor((128,), dtype=\"float32\"), w1: R.Tensor((10, 128), dtype=\"float32\"), b1: R.Tensor((10,), dtype=\"float32\")) -> R.Tensor((1, 10), dtype=\"float32\"):\n",
       "    # block 0\n",
       "    with R.dataflow():\n",
       "        lv0 = R.call_tir(\"env.linear\", (x, w0, b0), out_sinfo=R.Tensor((1, 128), dtype=\"float32\"))\n",
       "        lv1 = R.call_tir(\"env.relu\", (lv0,), out_sinfo=R.Tensor((1, 128), dtype=\"float32\"))\n",
       "        out = R.call_tir(\"env.linear\", (lv1, w1, b1), out_sinfo=R.Tensor((1, 10), dtype=\"float32\"))\n",
       "        R.output(out)\n",
       "    return out\n",
       "    "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.Code(MyModuleWithExternCall['main'].script(), language='python')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```pythoon\n",
    "R.call_tir(\"env.linear\", (x, w0, b0), relax.TensorStructInfo((1, 128), dtype='float32))\n",
    "```\n",
    "\"env.linear\"在模型执行期间的运行时函数 (runtime function) 的名称"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.1 注册运行时函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.register_func(\"env.linear\", override=True)\n",
    "def torch_linnear(x: tvm.nd.NDArray,\n",
    "                  w: tvm.nd.NDArray,\n",
    "                  b: tvm.nd.NDArray,\n",
    "                  out: tvm.nd.NDArray):\n",
    "    x_torch = torch.from_dlpack(x)\n",
    "    w_torch = torch.from_dlpack(w)\n",
    "    b_torch = torch.from_dlpack(b)\n",
    "    out_torch = torch.from_dlpack(out)\n",
    "    torch.mm(x_torch, w_torch.T, out=out_torch)\n",
    "    torch.add(out_torch, b_torch, out=out_torch)\n",
    "\n",
    "@tvm.register_func(\"env.relu\", override=True)\n",
    "def torch_relu(x: tvm.nd.NDArray,\n",
    "                out: tvm.nd.NDArray):\n",
    "    x_torch = torch.from_dlpack(x)\n",
    "    out_torch = torch.from_dlpack(out)\n",
    "    torch.maximum(x_torch, torch.Tensor([0.0]), out=out_torch)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from_dlpack 将 TVM NDArray 转换为 torch NDArray。 请注意，这是一个零拷贝转换，这意味着 Torch 阵列与 TVM NDArray 共享底层内存。 DLPack 是一种通用的交换标准，允许不同的框架交换 Tensor/NDArray 而无需参与数据复制。 from_dlpack API 由多个框架支持，是 Python 数组 API 标准的一部分"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2 Build and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModuleWithExternCall Prediction: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "ex_env = relax.vm.build(MyModuleWithExternCall, target='llvm')\n",
    "vm = relax.VirtualMachine(ex_env, tvm.cpu())\n",
    "\n",
    "nd_res = vm['main'](data_nd,\n",
    "                    nd_params['w0'],\n",
    "                    nd_params['b0'],\n",
    "                    nd_params['w1'],\n",
    "                    nd_params['b1'])\n",
    "\n",
    "pred_kind = np.argmax(nd_res.numpy(), axis=1)\n",
    "print(\"MyModuleWithExternCall Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Mixing TensorIR Code(TIRcode张量程序抽象) and Libraryes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixing version\n",
    "@tvm.script.ir_module\n",
    "class MyModuleMixture():\n",
    "    @T.prim_func\n",
    "    def linear0(X: T.Buffer[(1, 784), 'float32'],\n",
    "                W0: T.Buffer[(128, 784), 'float32'],\n",
    "                B0: T.Buffer[(128,), 'float32'],\n",
    "                Z: T.Buffer[(1, 128), 'float32']):\n",
    "        T.func_attr({\"global_symbol\": \"linear0\", \"tir.noalias\": True})\n",
    "        lv0 = T.alloc_buffer((1, 128), dtype='float32')\n",
    "        for i, j, k in T.grid(1, 128, 784):\n",
    "            with T.block(\"lv0\"):\n",
    "                vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
    "                with T.init():\n",
    "                    lv0[vi, vj] = T.float32(0)\n",
    "                lv0[vi, vj] = lv0[vi, vj] + X[vi, vk] * W0[vj, vk]\n",
    "        \n",
    "        for i, j in T.grid(1, 128):\n",
    "            with T.block(\"Z\"):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                Z[vi, vj] = T.max(lv0[vi, vj], T.float32(0))\n",
    "    \n",
    "    @R.function\n",
    "    def main(x: R.Tensor((1, 784), \"float32\"),\n",
    "             w0: R.Tensor((128, 784), \"float32\"),\n",
    "             b0: R.Tensor((128,), \"float32\"),\n",
    "             w1: R.Tensor((10, 128), \"float32\"),\n",
    "             b1: R.Tensor((10,), \"float32\")):\n",
    "        # block 0\n",
    "        with R.dataflow():\n",
    "            lv0 = R.call_tir(linear0, (x, w0, b0), relax.TensorStructInfo((1, 128), dtype=\"float32\"))\n",
    "            lv1 = R.call_tir(\"env.relu\", (lv0,), relax.TensorStructInfo((1, 128), dtype=\"float32\"))\n",
    "            out = R.call_tir(\"env.linear\", (lv1, w1, b1), relax.TensorStructInfo((1, 10), dtype=\"float32\"))\n",
    "            R.output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModuleMixture Prediction: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "ex = relax.vm.build(MyModuleMixture, target='llvm')\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu())\n",
    "\n",
    "nd_res = vm['main'](data_nd,\n",
    "                    nd_params['w0'],\n",
    "                    nd_params['b0'],\n",
    "                    nd_params['w1'],\n",
    "                    nd_params['b1'])\n",
    "\n",
    "pred_kind = np.argmax(nd_res.numpy(), axis=1)\n",
    "print(\"MyModuleMixture Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将参数绑定到IRModule(@tvm.script.ir_module)上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"nd\">@tvm</span><span class=\"o\">.</span><span class=\"n\">script</span><span class=\"o\">.</span><span class=\"n\">ir_module</span>\n",
       "<span class=\"k\">class</span> <span class=\"nc\">Module</span><span class=\"p\">:</span>\n",
       "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">linear0</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">784</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">W0</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">784</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">B0</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">Z</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">]):</span>\n",
       "        <span class=\"c1\"># function attr dict</span>\n",
       "        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">func_attr</span><span class=\"p\">({</span><span class=\"s2\">&quot;tir.noalias&quot;</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"s2\">&quot;global_symbol&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;linear0&quot;</span><span class=\"p\">})</span>\n",
       "        <span class=\"c1\"># body</span>\n",
       "        <span class=\"c1\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span class=\"n\">lv0</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">alloc_buffer</span><span class=\"p\">([</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"n\">k</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">784</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;lv0&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">,</span> <span class=\"n\">vk</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SSR&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">],</span> <span class=\"n\">W0</span><span class=\"p\">[</span><span class=\"n\">vj</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">lv0</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">init</span><span class=\"p\">():</span>\n",
       "                    <span class=\"n\">lv0</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n",
       "                <span class=\"n\">lv0</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">lv0</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">W0</span><span class=\"p\">[</span><span class=\"n\">vj</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">]</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Z&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">lv0</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Z</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">Z</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">lv0</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">))</span>\n",
       "    \n",
       "    <span class=\"nd\">@R</span><span class=\"o\">.</span><span class=\"n\">function</span>\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">main</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">784</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span> <span class=\"o\">-&gt;</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">):</span>\n",
       "        <span class=\"c1\"># block 0</span>\n",
       "        <span class=\"k\">with</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">dataflow</span><span class=\"p\">():</span>\n",
       "            <span class=\"n\">lv0</span> <span class=\"o\">=</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">call_tir</span><span class=\"p\">(</span><span class=\"n\">linear0</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">metadata</span><span class=\"p\">[</span><span class=\"s2\">&quot;relax.expr.Constant&quot;</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"n\">metadata</span><span class=\"p\">[</span><span class=\"s2\">&quot;relax.expr.Constant&quot;</span><span class=\"p\">][</span><span class=\"mi\">1</span><span class=\"p\">]),</span> <span class=\"n\">out_sinfo</span><span class=\"o\">=</span><span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span>\n",
       "            <span class=\"n\">lv1</span> <span class=\"o\">=</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">call_tir</span><span class=\"p\">(</span><span class=\"s2\">&quot;env.relu&quot;</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">lv0</span><span class=\"p\">,),</span> <span class=\"n\">out_sinfo</span><span class=\"o\">=</span><span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span>\n",
       "            <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">call_tir</span><span class=\"p\">(</span><span class=\"s2\">&quot;env.linear&quot;</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">lv1</span><span class=\"p\">,</span> <span class=\"n\">metadata</span><span class=\"p\">[</span><span class=\"s2\">&quot;relax.expr.Constant&quot;</span><span class=\"p\">][</span><span class=\"mi\">2</span><span class=\"p\">],</span> <span class=\"n\">metadata</span><span class=\"p\">[</span><span class=\"s2\">&quot;relax.expr.Constant&quot;</span><span class=\"p\">][</span><span class=\"mi\">3</span><span class=\"p\">]),</span> <span class=\"n\">out_sinfo</span><span class=\"o\">=</span><span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span>\n",
       "            <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">output</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">return</span> <span class=\"n\">out</span>\n",
       "        \n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{n+nd}{@tvm}\\PY{o}{.}\\PY{n}{script}\\PY{o}{.}\\PY{n}{ir\\PYZus{}module}\n",
       "\\PY{k}{class} \\PY{n+nc}{Module}\\PY{p}{:}\n",
       "    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n",
       "    \\PY{k}{def} \\PY{n+nf}{linear0}\\PY{p}{(}\\PY{n}{X}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{784}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{W0}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{784}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B0}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{Z}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} function attr dict}\n",
       "        \\PY{n}{T}\\PY{o}{.}\\PY{n}{func\\PYZus{}attr}\\PY{p}{(}\\PY{p}{\\PYZob{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{tir.noalias}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{k+kc}{True}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{global\\PYZus{}symbol}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{linear0}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{\\PYZcb{}}\\PY{p}{)}\n",
       "        \\PY{c+c1}{\\PYZsh{} body}\n",
       "        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{})}\n",
       "        \\PY{n}{lv0} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{alloc\\PYZus{}buffer}\\PY{p}{(}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{]}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "        \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{,} \\PY{n}{k} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{784}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{lv0}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{,} \\PY{n}{vk} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SSR}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{,} \\PY{n}{k}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{X}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]}\\PY{p}{,} \\PY{n}{W0}\\PY{p}{[}\\PY{n}{vj}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{lv0}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{init}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "                    \\PY{n}{lv0}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\n",
       "                \\PY{n}{lv0}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{lv0}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{X}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]} \\PY{o}{*} \\PY{n}{W0}\\PY{p}{[}\\PY{n}{vj}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]}\n",
       "        \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Z}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{lv0}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Z}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{Z}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{max}\\PY{p}{(}\\PY{n}{lv0}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\\PY{p}{)}\n",
       "    \n",
       "    \\PY{n+nd}{@R}\\PY{o}{.}\\PY{n}{function}\n",
       "    \\PY{k}{def} \\PY{n+nf}{main}\\PY{p}{(}\\PY{n}{x}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{784}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} block 0}\n",
       "        \\PY{k}{with} \\PY{n}{R}\\PY{o}{.}\\PY{n}{dataflow}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{n}{lv0} \\PY{o}{=} \\PY{n}{R}\\PY{o}{.}\\PY{n}{call\\PYZus{}tir}\\PY{p}{(}\\PY{n}{linear0}\\PY{p}{,} \\PY{p}{(}\\PY{n}{x}\\PY{p}{,} \\PY{n}{metadata}\\PY{p}{[}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{relax.expr.Constant}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\\PY{p}{,} \\PY{n}{metadata}\\PY{p}{[}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{relax.expr.Constant}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{]}\\PY{p}{)}\\PY{p}{,} \\PY{n}{out\\PYZus{}sinfo}\\PY{o}{=}\\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
       "            \\PY{n}{lv1} \\PY{o}{=} \\PY{n}{R}\\PY{o}{.}\\PY{n}{call\\PYZus{}tir}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{env.relu}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{(}\\PY{n}{lv0}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{out\\PYZus{}sinfo}\\PY{o}{=}\\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
       "            \\PY{n}{out} \\PY{o}{=} \\PY{n}{R}\\PY{o}{.}\\PY{n}{call\\PYZus{}tir}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{env.linear}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{(}\\PY{n}{lv1}\\PY{p}{,} \\PY{n}{metadata}\\PY{p}{[}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{relax.expr.Constant}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{[}\\PY{l+m+mi}{2}\\PY{p}{]}\\PY{p}{,} \\PY{n}{metadata}\\PY{p}{[}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{relax.expr.Constant}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{[}\\PY{l+m+mi}{3}\\PY{p}{]}\\PY{p}{)}\\PY{p}{,} \\PY{n}{out\\PYZus{}sinfo}\\PY{o}{=}\\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
       "            \\PY{n}{R}\\PY{o}{.}\\PY{n}{output}\\PY{p}{(}\\PY{n}{out}\\PY{p}{)}\n",
       "        \\PY{k}{return} \\PY{n}{out}\n",
       "        \n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "@tvm.script.ir_module\n",
       "class Module:\n",
       "    @T.prim_func\n",
       "    def linear0(X: T.Buffer[(1, 784), \"float32\"], W0: T.Buffer[(128, 784), \"float32\"], B0: T.Buffer[128, \"float32\"], Z: T.Buffer[(1, 128), \"float32\"]):\n",
       "        # function attr dict\n",
       "        T.func_attr({\"tir.noalias\": True, \"global_symbol\": \"linear0\"})\n",
       "        # body\n",
       "        # with T.block(\"root\")\n",
       "        lv0 = T.alloc_buffer([1, 128], dtype=\"float32\")\n",
       "        for i, j, k in T.grid(1, 128, 784):\n",
       "            with T.block(\"lv0\"):\n",
       "                vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
       "                T.reads(X[vi, vk], W0[vj, vk])\n",
       "                T.writes(lv0[vi, vj])\n",
       "                with T.init():\n",
       "                    lv0[vi, vj] = T.float32(0)\n",
       "                lv0[vi, vj] = lv0[vi, vj] + X[vi, vk] * W0[vj, vk]\n",
       "        for i, j in T.grid(1, 128):\n",
       "            with T.block(\"Z\"):\n",
       "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
       "                T.reads(lv0[vi, vj])\n",
       "                T.writes(Z[vi, vj])\n",
       "                Z[vi, vj] = T.max(lv0[vi, vj], T.float32(0))\n",
       "    \n",
       "    @R.function\n",
       "    def main(x: R.Tensor((1, 784), dtype=\"float32\")) -> R.Tensor((1, 10), dtype=\"float32\"):\n",
       "        # block 0\n",
       "        with R.dataflow():\n",
       "            lv0 = R.call_tir(linear0, (x, metadata[\"relax.expr.Constant\"][0], metadata[\"relax.expr.Constant\"][1]), out_sinfo=R.Tensor((1, 128), dtype=\"float32\"))\n",
       "            lv1 = R.call_tir(\"env.relu\", (lv0,), out_sinfo=R.Tensor((1, 128), dtype=\"float32\"))\n",
       "            out = R.call_tir(\"env.linear\", (lv1, metadata[\"relax.expr.Constant\"][2], metadata[\"relax.expr.Constant\"][3]), out_sinfo=R.Tensor((1, 10), dtype=\"float32\"))\n",
       "            R.output(out)\n",
       "        return out\n",
       "        "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyModuleWithParams = relax.transform.BindParams(\"main\", nd_params)(MyModuleMixture)\n",
    "IPython.display.Code(MyModuleWithParams.script(), language='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModuleWithParams Prediction: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "ex = relax.vm.build(MyModuleWithParams, target='llvm')\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu())\n",
    "\n",
    "nd_res = vm['main'](data_nd)\n",
    "\n",
    "pred_kind = np.argmax(nd_res.numpy(), axis=1)\n",
    "print(\"MyModuleWithParams Prediction:\", class_names[pred_kind[0]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Discuss\n",
    "MLC 的共同主题：MLC 过程是在不同的抽象表示之间执行并在它们之间进行转换；\\\n",
    "端到端执行中有许多可能的转换。 例如，我们可以使用 MyModuleMixture 中的 TensorIR 函数，并使用上一课中讲授的调度操作更改 linear0 函数。 在其他情况下，我们可能希望将高层模型执行转换为库函数调用和 TensorIR 函数的混合体。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10 总结\n",
    "计算图抽象有助于将元张量函数拼接在一起以进行端到端执行。\n",
    "\n",
    "Relax 抽象的关键要素包括\n",
    "\n",
    "1. call_tir 构造，将目标传递规范的元函数嵌入到计算图中\n",
    "2. Dataflow block\n",
    "\n",
    "计算图允许调用环境库函数和 TensorIR 函数（参数绑定relax.transform.BindParams）。\n",
    "\n",
    "搞懂tvm.build 与 relax.vm.build之间关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df7b789d6764113f3eb4ff8e192e7912fbf893c46539f75332048503ce5ba603"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
