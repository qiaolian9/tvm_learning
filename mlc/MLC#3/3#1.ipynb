{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 端到端模型执行\n",
    "## 3.1 前言\n",
    "什么是可能的张量函数抽象表达形式？\\\n",
    "什么是可能的张量函数变换？"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import IPython\n",
    "import tvm\n",
    "import numpy as np\n",
    "from tvm.script import tir as T\n",
    "from tvm.script import  relax as R\n",
    "from tvm.ir.module import IRModule\n",
    "from tvm import relax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "import torch\n",
    "import torchvision\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "img, label = next(iter(test_loader))\n",
    "img = img.reshape(1, 28, 28).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Sandal\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "print(\"Class:\", class_names[label[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-08 16:01:07--  https://github.com/mlc-ai/web-data/raw/main/models/fasionmnist_mlp_params.pkl\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/mlc-ai/web-data/main/models/fasionmnist_mlp_params.pkl [following]\n",
      "--2023-02-08 16:01:07--  https://raw.githubusercontent.com/mlc-ai/web-data/main/models/fasionmnist_mlp_params.pkl\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8001::154, 2606:50c0:8002::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 407396 (398K) [application/octet-stream]\n",
      "Saving to: ‘fasionmnist_mlp_params.pkl.5’\n",
      "\n",
      "fasionmnist_mlp_par 100%[===================>] 397.85K  1.15MB/s    in 0.3s    \n",
      "\n",
      "2023-02-08 16:01:08 (1.15 MB/s) - ‘fasionmnist_mlp_params.pkl.5’ saved [407396/407396]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ckpt\n",
    "# Hide outputs\n",
    "!wget https://github.com/mlc-ai/web-data/raw/main/models/fasionmnist_mlp_params.pkl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 端到端模型整合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear -> relu -> Linear\n",
    "# numpy version\n",
    "def numpy_mlp(data, w0, b0, w1, b1):\n",
    "    # print(data.shape, w0.shape)\n",
    "    lv0 = data @ w0.T + b0\n",
    "    lv1 = np.maximum(lv0, 0)\n",
    "    lv2 = lv1 @ w1.T + b1\n",
    "    return lv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-15.626809  -27.425406  -16.597683  -10.684554  -29.60807    16.692785\n",
      "  -28.415834   -7.960229   -1.7843808  -6.674226 ]]\n",
      "[5]\n",
      "numpy mlp prediction: Sandal\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "mlp_params = pkl.load(open(\"/staff/qiaoliang/ACSA科研项目/tvm_learning/mlc/fasionmnist_mlp_params.pkl\", \"rb\"))\n",
    "\n",
    "res = numpy_mlp(img.reshape(1, 784),\n",
    "                mlp_params[\"w0\"],\n",
    "                mlp_params[\"b0\"],\n",
    "                mlp_params[\"w1\"],\n",
    "                mlp_params[\"b1\"])\n",
    "\n",
    "print(res)\n",
    "pred_kind = res.argmax(axis=1)\n",
    "print(pred_kind)\n",
    "print(\"numpy mlp prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level Numpy MLP Prediction: Sandal\n"
     ]
    }
   ],
   "source": [
    "# low level numpy version\n",
    "def lnumpy_linear0(X: np.ndarray, W: np.ndarray, B: np.ndarray, Z: np.ndarray):\n",
    "    Y = np.empty((1, 128), 'float32')\n",
    "    for i in range(1):\n",
    "        for j in range(128):\n",
    "            for k in range(784):\n",
    "                if k == 0 :\n",
    "                    Y[i, j] = 0\n",
    "                Y[i, j] = Y[i, j] + X[i, k] * W[j, k]\n",
    "    \n",
    "    for i in range(1):\n",
    "        for j in range(128):\n",
    "            Z[i, j] = Y[i, j] + B[j]\n",
    "\n",
    "def lnumpy_relu(X: np.ndarray, Z: np.ndarray):\n",
    "    for i in range(1):\n",
    "        for j in range(128):\n",
    "            Z[i, j] = np.maximum(X[i, j], 0)\n",
    "\n",
    "def lnumpy_linear1(X: np.ndarray, W: np.ndarray, B: np.ndarray, Z: np.ndarray):\n",
    "    Y =  np.empty((1, 10), dtype='float32')\n",
    "    for i in range(1):\n",
    "        for j in range(10):\n",
    "            for k in range(128):\n",
    "                if k == 0:\n",
    "                    Y[i, j] = 0\n",
    "                Y[i, j] = Y[i, j] + X[i, k] * W[j, k]\n",
    "    \n",
    "    for i in range(1):\n",
    "        for j in range(10):\n",
    "            Z[i, j] = Y[i, j] + B[j]\n",
    "\n",
    "def lnumpy_mlp(X: np.ndarray,\n",
    "               W0: np.ndarray,\n",
    "               B0: np.ndarray,\n",
    "               W1: np.ndarray,\n",
    "               B1: np.ndarray):\n",
    "    lv1 = np.empty((1, 128), dtype='float32')\n",
    "    lv2 = np.empty((1, 128), dtype='float32')\n",
    "    out = np.empty((1, 10), dtype='float32')\n",
    "    lnumpy_linear0(X, W0, B0, lv1)\n",
    "    lnumpy_relu(lv1, lv2)\n",
    "    lnumpy_linear1(lv2, W1, B1, out)\n",
    "    return out\n",
    "\n",
    "res_lnumpy = lnumpy_mlp(img.reshape(1, 784), \n",
    "                        mlp_params[\"w0\"],\n",
    "                        mlp_params[\"b0\"],\n",
    "                        mlp_params[\"w1\"],\n",
    "                        mlp_params[\"b1\"])\n",
    "\n",
    "pred_kind_lnumpy = res_lnumpy.argmax(axis=1)\n",
    "print(\"Low-level Numpy MLP Prediction:\", class_names[pred_kind_lnumpy[0]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 TVMScript中构建IRModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorIR\n",
    "# Method 1: IRModule ----> tvm.build ----> rt_lib\n",
    "@tvm.script.ir_module\n",
    "class MyModule():\n",
    "    @T.prim_func\n",
    "    def relu(X: T.Buffer[(1, 128), 'float32'],\n",
    "             Z: T.Buffer[(1, 128), 'float32']):\n",
    "        T.func_attr({\"global_symbol\": \"relu\", \"tir.noalias\": True})\n",
    "        for i, j in T.grid(1, 128):\n",
    "            with T.block('Z'):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                Z[vi, vj] = T.max(X[i, j], T.float32(0))\n",
    "    \n",
    "    @T.prim_func\n",
    "    def linear0(X: T.Buffer[(1, 784), 'float32'],\n",
    "                W: T.Buffer[(128, 784), 'float32'],\n",
    "                B: T.Buffer[(128), 'float32'],\n",
    "                Z: T.Buffer[(1, 128), 'float32']):\n",
    "        T.func_attr({\"global_symbol\": \"linear0\", \"tir.noalias\": True})\n",
    "        Y = T.alloc_buffer((1, 128), dtype='float32')\n",
    "        for i, j, k in T.grid(1, 128, 784):\n",
    "            with T.block(\"Y\"):\n",
    "                vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
    "                with T.init():\n",
    "                    Y[vi, vj] = T.float32(0)\n",
    "                Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk]\n",
    "        \n",
    "        for i, j in T.grid(1, 128):\n",
    "            with T.block(\"Z\"):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                Z[vi, vj] = Y[vi, vj] + B[vj]\n",
    "    \n",
    "    @T.prim_func\n",
    "    def linear1(X: T.Buffer[(1, 128), 'float32'],\n",
    "                W: T.Buffer[(10, 128), 'float32'],\n",
    "                B: T.Buffer[(10), 'float32'],\n",
    "                Z: T.Buffer[(1, 10), 'float32']):\n",
    "        T.func_attr({\"global_symbol\": \"linear1\", \"tir.noalias\": True})\n",
    "        Y = T.alloc_buffer((1, 10), dtype='float32')\n",
    "        for i, j, k in T.grid(1, 10, 128):\n",
    "            with T.block(\"Y\"):\n",
    "                vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
    "                with T.init():\n",
    "                    Y[vi, vj] = T.float32(0)\n",
    "                Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk]\n",
    "        \n",
    "        for i, j in T.grid(1, 10):\n",
    "            with T.block(\"Z\"):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                Z[vi, vj] = Y[vi, vj] + B[vj]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorIR MLP Prediction: Sandal\n"
     ]
    }
   ],
   "source": [
    "rt_lib = tvm.build(MyModule, target='llvm')\n",
    "func_0 = rt_lib['linear0']\n",
    "func_1 = rt_lib['relu']\n",
    "func_2 = rt_lib['linear1']\n",
    "\n",
    "lv1 = tvm.nd.empty((1, 128), dtype='float32')\n",
    "lv2 = tvm.nd.empty((1, 128), dtype='float32')\n",
    "res_tvm = tvm.nd.empty((1, 10), dtype='float32')\n",
    "func_0(tvm.nd.array(img.reshape(1, 784)), tvm.nd.array(mlp_params[\"w0\"]), tvm.nd.array(mlp_params[\"b0\"]), lv1)\n",
    "func_1(lv1, lv2)\n",
    "func_2(lv2, tvm.nd.array(mlp_params[\"w1\"]), tvm.nd.array(mlp_params[\"b1\"]), res_tvm)\n",
    "\n",
    "pred_kind_tvm = res_tvm.numpy().argmax(axis=1)\n",
    "print(\"TensorIR MLP Prediction:\", class_names[pred_kind_tvm[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyModule:\n",
    "    @T.prim_func\n",
    "    def relu0(X: T.Buffer[(1, 128), \"float32\"],\n",
    "              Y: T.Buffer[(1, 128), \"float32\"]):\n",
    "        # function attr dict\n",
    "        T.func_attr({\"global_symbol\": \"relu0\", \"tir.noalias\": True})\n",
    "        for i, j in T.grid(1, 128):\n",
    "            with T.block(\"Y\"):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                Y[vi, vj] = T.max(X[vi, vj], T.float32(0))\n",
    "\n",
    "    @T.prim_func\n",
    "    def linear0(X: T.Buffer[(1, 784), \"float32\"],\n",
    "                W: T.Buffer[(128, 784), \"float32\"],\n",
    "                B: T.Buffer[(128,), \"float32\"],\n",
    "                Z: T.Buffer[(1, 128), \"float32\"]):\n",
    "        T.func_attr({\"global_symbol\": \"linear0\", \"tir.noalias\": True})\n",
    "        Y = T.alloc_buffer((1, 128), \"float32\")\n",
    "        for i, j, k in T.grid(1, 128, 784):\n",
    "            with T.block(\"Y\"):\n",
    "                vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
    "                with T.init():\n",
    "                    Y[vi, vj] = T.float32(0)\n",
    "                Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk]\n",
    "\n",
    "        for i, j in T.grid(1, 128):\n",
    "            with T.block(\"Z\"):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                Z[vi, vj] =  Y[vi, vj] + B[vj]\n",
    "\n",
    "    @T.prim_func\n",
    "    def linear1(X: T.Buffer[(1, 128), \"float32\"],\n",
    "                W: T.Buffer[(10, 128), \"float32\"],\n",
    "                B: T.Buffer[(10,), \"float32\"],\n",
    "                Z: T.Buffer[(1, 10), \"float32\"]):\n",
    "        T.func_attr({\"global_symbol\": \"linear1\", \"tir.noalias\": True})\n",
    "        Y = T.alloc_buffer((1, 10), \"float32\")\n",
    "        for i, j, k in T.grid(1, 10, 128):\n",
    "            with T.block(\"Y\"):\n",
    "                vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
    "                with T.init():\n",
    "                    Y[vi, vj] = T.float32(0)\n",
    "                Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk]\n",
    "\n",
    "        for i, j in T.grid(1, 10):\n",
    "            with T.block(\"Z\"):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                Z[vi, vj] = Y[vi, vj] + B[vj]\n",
    "\n",
    "    @R.function\n",
    "    def main(x: R.Tensor((1, 784), \"float32\"),\n",
    "             w0: R.Tensor((128, 784), \"float32\"),\n",
    "             b0: R.Tensor((128,), \"float32\"),\n",
    "             w1: R.Tensor((10, 128), \"float32\"),\n",
    "             b1: R.Tensor((10,), \"float32\")):\n",
    "        with R.dataflow():\n",
    "            lv0 = R.call_tir(linear0, (x, w0, b0), relax.TensorStructInfo((1, 128), dtype=\"float32\"))\n",
    "            lv1 = R.call_tir(relu0, (lv0,), relax.TensorStructInfo((1, 128), dtype=\"float32\"))\n",
    "            out = R.call_tir(linear1, (lv1, w1, b1), relax.TensorStructInfo((1, 10), dtype=\"float32\"))\n",
    "            R.output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relax.expr.Function(0x555a17484f80)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyModule['main']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 call_tir\n",
    "```python\n",
    "lv0 = R.call_tir(linear0, (X, W0, B0), (1, 128))\n",
    "```\n",
    "```python\n",
    "def lnumpy_call_tir(prim_func, inputs, shape):\n",
    "    res = np.empty(shape)\n",
    "    prim_func(*input, res)\n",
    "    return res\n",
    "```\n",
    "\n",
    "call_tir 接受一个元函数 (prim_func) 的输入列表，并分配一个输出张量res，然后将输入和输出传递给prim_func。 执行 prim_func 后，结果会填充到 res 中，然后我们可以返回结果。\\\n",
    "\n",
    "**为什么我们需要 call_tir？** 这是因为我们的元张量函数采用以下调用约定：**目标传递** -> 输入和输出在外部显式分配并传递给底层元函数\n",
    "```python\n",
    "def low_level_prim_func(in0, in1, ..., out):\n",
    "    # to Do\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level Numpy with CallTIR Prediction: Sandal\n"
     ]
    }
   ],
   "source": [
    "def lnumpy_call_tir(prim_func, inputs, shape, dtype):\n",
    "    res = np.empty(shape, dtype=dtype)\n",
    "    prim_func(*inputs, res)\n",
    "    return res\n",
    "    \n",
    "def lnumpy_mlp_with_call_tir(X: np.ndarray, W0: np.ndarray, B0: np.ndarray, W1: np.ndarray, B1: np.ndarray):\n",
    "    lv0 = lnumpy_call_tir(lnumpy_linear0, (X, W0, B0), (1, 128), 'float32')\n",
    "    lv1 = lnumpy_call_tir(lnumpy_relu, (lv0,), (1, 128), 'float32')\n",
    "    res = lnumpy_call_tir(lnumpy_linear1, (lv1, W1, B1), (1, 10), 'float32')\n",
    "    return res\n",
    "\n",
    "res = lnumpy_mlp_with_call_tir(img.reshape(1, 784),\n",
    "                      mlp_params['w0'],\n",
    "                      mlp_params['b0'],\n",
    "                      mlp_params['w1'],\n",
    "                      mlp_params['b1'])\n",
    "\n",
    "pred_kind_lnumpy_with_call_tir = res.argmax(axis=1)\n",
    "print(\"Low-level Numpy with CallTIR Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 Dataflow Block\n",
    "\n",
    "**回看**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 构建并运行模型\n",
    "\n",
    "```python\n",
    "IRModule --> @T.prim_func & @R.function\n",
    "1. @T.prim_func: tvm.build(IRModule) ---> rt_lib(tvm.driver.build_module.OperatorModule) ---> rt_lib[\"prim_func\"](tvm.runtime.packed_func.PackedFunc)\n",
    "2. @R.function: relax.vm.build(IRModule) ---> ex(tvm.relax.vm.Executable) ---> relax.VirtualMachine(ex, tvm.cpu()) ---> vm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"nd\">@tvm</span><span class=\"o\">.</span><span class=\"n\">script</span><span class=\"o\">.</span><span class=\"n\">ir_module</span>\n",
       "<span class=\"k\">class</span> <span class=\"nc\">Module</span><span class=\"p\">:</span>\n",
       "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">linear0</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">784</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">W</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">784</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">Z</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">]):</span>\n",
       "        <span class=\"c1\"># function attr dict</span>\n",
       "        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">func_attr</span><span class=\"p\">({</span><span class=\"s2\">&quot;tir.noalias&quot;</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"s2\">&quot;global_symbol&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;linear0&quot;</span><span class=\"p\">})</span>\n",
       "        <span class=\"c1\"># body</span>\n",
       "        <span class=\"c1\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">alloc_buffer</span><span class=\"p\">([</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"n\">k</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">784</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Y&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">,</span> <span class=\"n\">vk</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SSR&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">],</span> <span class=\"n\">W</span><span class=\"p\">[</span><span class=\"n\">vj</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">init</span><span class=\"p\">():</span>\n",
       "                    <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n",
       "                <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">W</span><span class=\"p\">[</span><span class=\"n\">vj</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">]</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Z&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Z</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">Z</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vj</span><span class=\"p\">]</span>\n",
       "    \n",
       "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">relu0</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">Y</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">]):</span>\n",
       "        <span class=\"c1\"># function attr dict</span>\n",
       "        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">func_attr</span><span class=\"p\">({</span><span class=\"s2\">&quot;tir.noalias&quot;</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"s2\">&quot;global_symbol&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;relu0&quot;</span><span class=\"p\">})</span>\n",
       "        <span class=\"c1\"># body</span>\n",
       "        <span class=\"c1\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Y&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">))</span>\n",
       "    \n",
       "    <span class=\"nd\">@R</span><span class=\"o\">.</span><span class=\"n\">function</span>\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">main</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">784</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">w0</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">784</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">b0</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">128</span><span class=\"p\">,),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">w1</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">b1</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">10</span><span class=\"p\">,),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span> <span class=\"o\">-&gt;</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">):</span>\n",
       "        <span class=\"c1\"># block 0</span>\n",
       "        <span class=\"k\">with</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">dataflow</span><span class=\"p\">():</span>\n",
       "            <span class=\"n\">lv0</span> <span class=\"o\">=</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">call_tir</span><span class=\"p\">(</span><span class=\"n\">linear0</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">w0</span><span class=\"p\">,</span> <span class=\"n\">b0</span><span class=\"p\">),</span> <span class=\"n\">out_sinfo</span><span class=\"o\">=</span><span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span>\n",
       "            <span class=\"n\">lv1</span> <span class=\"o\">=</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">call_tir</span><span class=\"p\">(</span><span class=\"n\">relu0</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">lv0</span><span class=\"p\">,),</span> <span class=\"n\">out_sinfo</span><span class=\"o\">=</span><span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span>\n",
       "            <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">call_tir</span><span class=\"p\">(</span><span class=\"n\">linear1</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">lv1</span><span class=\"p\">,</span> <span class=\"n\">w1</span><span class=\"p\">,</span> <span class=\"n\">b1</span><span class=\"p\">),</span> <span class=\"n\">out_sinfo</span><span class=\"o\">=</span><span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span>\n",
       "            <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">output</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">return</span> <span class=\"n\">out</span>\n",
       "        \n",
       "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">linear1</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">W</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">Z</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">]):</span>\n",
       "        <span class=\"c1\"># function attr dict</span>\n",
       "        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">func_attr</span><span class=\"p\">({</span><span class=\"s2\">&quot;tir.noalias&quot;</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"s2\">&quot;global_symbol&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;linear1&quot;</span><span class=\"p\">})</span>\n",
       "        <span class=\"c1\"># body</span>\n",
       "        <span class=\"c1\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">alloc_buffer</span><span class=\"p\">([</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"n\">k</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Y&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">,</span> <span class=\"n\">vk</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SSR&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">],</span> <span class=\"n\">W</span><span class=\"p\">[</span><span class=\"n\">vj</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">init</span><span class=\"p\">():</span>\n",
       "                    <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n",
       "                <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">W</span><span class=\"p\">[</span><span class=\"n\">vj</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">]</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Z&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Z</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">Z</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vj</span><span class=\"p\">]</span>\n",
       "    \n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{n+nd}{@tvm}\\PY{o}{.}\\PY{n}{script}\\PY{o}{.}\\PY{n}{ir\\PYZus{}module}\n",
       "\\PY{k}{class} \\PY{n+nc}{Module}\\PY{p}{:}\n",
       "    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n",
       "    \\PY{k}{def} \\PY{n+nf}{linear0}\\PY{p}{(}\\PY{n}{X}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{784}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{W}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{784}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{Z}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} function attr dict}\n",
       "        \\PY{n}{T}\\PY{o}{.}\\PY{n}{func\\PYZus{}attr}\\PY{p}{(}\\PY{p}{\\PYZob{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{tir.noalias}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{k+kc}{True}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{global\\PYZus{}symbol}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{linear0}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{\\PYZcb{}}\\PY{p}{)}\n",
       "        \\PY{c+c1}{\\PYZsh{} body}\n",
       "        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{})}\n",
       "        \\PY{n}{Y} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{alloc\\PYZus{}buffer}\\PY{p}{(}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{]}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "        \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{,} \\PY{n}{k} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{784}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Y}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{,} \\PY{n}{vk} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SSR}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{,} \\PY{n}{k}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{X}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]}\\PY{p}{,} \\PY{n}{W}\\PY{p}{[}\\PY{n}{vj}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{init}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "                    \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\n",
       "                \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{X}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]} \\PY{o}{*} \\PY{n}{W}\\PY{p}{[}\\PY{n}{vj}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]}\n",
       "        \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Z}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Z}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{Z}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vj}\\PY{p}{]}\n",
       "    \n",
       "    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n",
       "    \\PY{k}{def} \\PY{n+nf}{relu0}\\PY{p}{(}\\PY{n}{X}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{Y}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} function attr dict}\n",
       "        \\PY{n}{T}\\PY{o}{.}\\PY{n}{func\\PYZus{}attr}\\PY{p}{(}\\PY{p}{\\PYZob{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{tir.noalias}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{k+kc}{True}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{global\\PYZus{}symbol}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{relu0}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{\\PYZcb{}}\\PY{p}{)}\n",
       "        \\PY{c+c1}{\\PYZsh{} body}\n",
       "        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{})}\n",
       "        \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Y}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{X}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{max}\\PY{p}{(}\\PY{n}{X}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\\PY{p}{)}\n",
       "    \n",
       "    \\PY{n+nd}{@R}\\PY{o}{.}\\PY{n}{function}\n",
       "    \\PY{k}{def} \\PY{n+nf}{main}\\PY{p}{(}\\PY{n}{x}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{784}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{w0}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{784}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{b0}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{w1}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{b1}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} block 0}\n",
       "        \\PY{k}{with} \\PY{n}{R}\\PY{o}{.}\\PY{n}{dataflow}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{n}{lv0} \\PY{o}{=} \\PY{n}{R}\\PY{o}{.}\\PY{n}{call\\PYZus{}tir}\\PY{p}{(}\\PY{n}{linear0}\\PY{p}{,} \\PY{p}{(}\\PY{n}{x}\\PY{p}{,} \\PY{n}{w0}\\PY{p}{,} \\PY{n}{b0}\\PY{p}{)}\\PY{p}{,} \\PY{n}{out\\PYZus{}sinfo}\\PY{o}{=}\\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
       "            \\PY{n}{lv1} \\PY{o}{=} \\PY{n}{R}\\PY{o}{.}\\PY{n}{call\\PYZus{}tir}\\PY{p}{(}\\PY{n}{relu0}\\PY{p}{,} \\PY{p}{(}\\PY{n}{lv0}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{out\\PYZus{}sinfo}\\PY{o}{=}\\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
       "            \\PY{n}{out} \\PY{o}{=} \\PY{n}{R}\\PY{o}{.}\\PY{n}{call\\PYZus{}tir}\\PY{p}{(}\\PY{n}{linear1}\\PY{p}{,} \\PY{p}{(}\\PY{n}{lv1}\\PY{p}{,} \\PY{n}{w1}\\PY{p}{,} \\PY{n}{b1}\\PY{p}{)}\\PY{p}{,} \\PY{n}{out\\PYZus{}sinfo}\\PY{o}{=}\\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
       "            \\PY{n}{R}\\PY{o}{.}\\PY{n}{output}\\PY{p}{(}\\PY{n}{out}\\PY{p}{)}\n",
       "        \\PY{k}{return} \\PY{n}{out}\n",
       "        \n",
       "    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n",
       "    \\PY{k}{def} \\PY{n+nf}{linear1}\\PY{p}{(}\\PY{n}{X}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{W}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{Z}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} function attr dict}\n",
       "        \\PY{n}{T}\\PY{o}{.}\\PY{n}{func\\PYZus{}attr}\\PY{p}{(}\\PY{p}{\\PYZob{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{tir.noalias}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{k+kc}{True}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{global\\PYZus{}symbol}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{linear1}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{\\PYZcb{}}\\PY{p}{)}\n",
       "        \\PY{c+c1}{\\PYZsh{} body}\n",
       "        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{})}\n",
       "        \\PY{n}{Y} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{alloc\\PYZus{}buffer}\\PY{p}{(}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{]}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "        \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{,} \\PY{n}{k} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Y}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{,} \\PY{n}{vk} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SSR}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{,} \\PY{n}{k}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{X}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]}\\PY{p}{,} \\PY{n}{W}\\PY{p}{[}\\PY{n}{vj}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{init}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "                    \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\n",
       "                \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{X}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]} \\PY{o}{*} \\PY{n}{W}\\PY{p}{[}\\PY{n}{vj}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]}\n",
       "        \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Z}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Z}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{Z}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vj}\\PY{p}{]}\n",
       "    \n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "@tvm.script.ir_module\n",
       "class Module:\n",
       "    @T.prim_func\n",
       "    def linear0(X: T.Buffer[(1, 784), \"float32\"], W: T.Buffer[(128, 784), \"float32\"], B: T.Buffer[128, \"float32\"], Z: T.Buffer[(1, 128), \"float32\"]):\n",
       "        # function attr dict\n",
       "        T.func_attr({\"tir.noalias\": True, \"global_symbol\": \"linear0\"})\n",
       "        # body\n",
       "        # with T.block(\"root\")\n",
       "        Y = T.alloc_buffer([1, 128], dtype=\"float32\")\n",
       "        for i, j, k in T.grid(1, 128, 784):\n",
       "            with T.block(\"Y\"):\n",
       "                vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
       "                T.reads(X[vi, vk], W[vj, vk])\n",
       "                T.writes(Y[vi, vj])\n",
       "                with T.init():\n",
       "                    Y[vi, vj] = T.float32(0)\n",
       "                Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk]\n",
       "        for i, j in T.grid(1, 128):\n",
       "            with T.block(\"Z\"):\n",
       "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
       "                T.reads(Y[vi, vj], B[vj])\n",
       "                T.writes(Z[vi, vj])\n",
       "                Z[vi, vj] = Y[vi, vj] + B[vj]\n",
       "    \n",
       "    @T.prim_func\n",
       "    def relu0(X: T.Buffer[(1, 128), \"float32\"], Y: T.Buffer[(1, 128), \"float32\"]):\n",
       "        # function attr dict\n",
       "        T.func_attr({\"tir.noalias\": True, \"global_symbol\": \"relu0\"})\n",
       "        # body\n",
       "        # with T.block(\"root\")\n",
       "        for i, j in T.grid(1, 128):\n",
       "            with T.block(\"Y\"):\n",
       "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
       "                T.reads(X[vi, vj])\n",
       "                T.writes(Y[vi, vj])\n",
       "                Y[vi, vj] = T.max(X[vi, vj], T.float32(0))\n",
       "    \n",
       "    @R.function\n",
       "    def main(x: R.Tensor((1, 784), dtype=\"float32\"), w0: R.Tensor((128, 784), dtype=\"float32\"), b0: R.Tensor((128,), dtype=\"float32\"), w1: R.Tensor((10, 128), dtype=\"float32\"), b1: R.Tensor((10,), dtype=\"float32\")) -> R.Tensor((1, 10), dtype=\"float32\"):\n",
       "        # block 0\n",
       "        with R.dataflow():\n",
       "            lv0 = R.call_tir(linear0, (x, w0, b0), out_sinfo=R.Tensor((1, 128), dtype=\"float32\"))\n",
       "            lv1 = R.call_tir(relu0, (lv0,), out_sinfo=R.Tensor((1, 128), dtype=\"float32\"))\n",
       "            out = R.call_tir(linear1, (lv1, w1, b1), out_sinfo=R.Tensor((1, 10), dtype=\"float32\"))\n",
       "            R.output(out)\n",
       "        return out\n",
       "        \n",
       "    @T.prim_func\n",
       "    def linear1(X: T.Buffer[(1, 128), \"float32\"], W: T.Buffer[(10, 128), \"float32\"], B: T.Buffer[10, \"float32\"], Z: T.Buffer[(1, 10), \"float32\"]):\n",
       "        # function attr dict\n",
       "        T.func_attr({\"tir.noalias\": True, \"global_symbol\": \"linear1\"})\n",
       "        # body\n",
       "        # with T.block(\"root\")\n",
       "        Y = T.alloc_buffer([1, 10], dtype=\"float32\")\n",
       "        for i, j, k in T.grid(1, 10, 128):\n",
       "            with T.block(\"Y\"):\n",
       "                vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
       "                T.reads(X[vi, vk], W[vj, vk])\n",
       "                T.writes(Y[vi, vj])\n",
       "                with T.init():\n",
       "                    Y[vi, vj] = T.float32(0)\n",
       "                Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk]\n",
       "        for i, j in T.grid(1, 10):\n",
       "            with T.block(\"Z\"):\n",
       "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
       "                T.reads(Y[vi, vj], B[vj])\n",
       "                T.writes(Z[vi, vj])\n",
       "                Z[vi, vj] = Y[vi, vj] + B[vj]\n",
       "    "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.Code(MyModule.script(), language='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tvm.relax.vm.Executable,\n",
       " tvm.driver.build_module.OperatorModule,\n",
       " tvm.runtime.packed_func.PackedFunc,\n",
       " tvm.runtime.packed_func.PackedFunc)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = relax.vm.build(MyModule, target=\"llvm\")\n",
    "# build 函数会给我们一个可执行文件（译者注：“可执行文件”并非传统操作系统中的可执行文件，不能直接在系统中运行，\\\n",
    "# 而是针对Relax VM设计的一种文件格式）。 我们可以初始化一个虚拟机执行器，使我们能够运行该函数。 此外，我们将传入第二个参数，指示我们要在哪个设备上运行端到端执行。\n",
    "type(ex), type(rt_lib), type(func_0), type(rt_lib['linear0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm = relax.VirtualMachine(ex, tvm.cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nd = tvm.nd.array(img.reshape(1, 784))\n",
    "nd_params = {k: tvm.nd.array(v) for k, v in mlp_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-15.626811  -27.425406  -16.59769   -10.684552  -29.608068   16.69279\n",
      "  -28.415836   -7.960229   -1.7843763  -6.674225 ]]\n"
     ]
    }
   ],
   "source": [
    "nd_res = vm[\"main\"](data_nd,\n",
    "                    nd_params[\"w0\"],\n",
    "                    nd_params[\"b0\"],\n",
    "                    nd_params[\"w1\"],\n",
    "                    nd_params[\"b1\"])\n",
    "print(nd_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModule Prediction: Sandal\n"
     ]
    }
   ],
   "source": [
    "pred_kind = np.argmax(nd_res.numpy(), axis=1)\n",
    "print(\"MyModule Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 在环境中集成现有运行库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyModuleWithExternCall:\n",
    "    @R.function\n",
    "    def main(x: R.Tensor((1, 784), \"float32\"),\n",
    "             w0: R.Tensor((128, 784), \"float32\"),\n",
    "             b0: R.Tensor((128,), \"float32\"),\n",
    "             w1: R.Tensor((10, 128), \"float32\"),\n",
    "             b1: R.Tensor((10,), \"float32\")):\n",
    "        # block 0\n",
    "        with R.dataflow():\n",
    "            lv0 = R.call_tir(\"env.linear\", (x, w0, b0), relax.TensorStructInfo((1, 128), dtype=\"float32\"))\n",
    "            lv1 = R.call_tir(\"env.relu\", (lv0,), relax.TensorStructInfo((1, 128), dtype=\"float32\"))\n",
    "            out = R.call_tir(\"env.linear\", (lv1, w1, b1), relax.TensorStructInfo((1, 10), dtype=\"float32\"))\n",
    "            R.output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"nd\">@R</span><span class=\"o\">.</span><span class=\"n\">function</span>\n",
       "<span class=\"k\">def</span> <span class=\"nf\">main</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">784</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">w0</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">784</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">b0</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">128</span><span class=\"p\">,),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">w1</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">b1</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">10</span><span class=\"p\">,),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span> <span class=\"o\">-&gt;</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">):</span>\n",
       "    <span class=\"c1\"># block 0</span>\n",
       "    <span class=\"k\">with</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">dataflow</span><span class=\"p\">():</span>\n",
       "        <span class=\"n\">lv0</span> <span class=\"o\">=</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">call_tir</span><span class=\"p\">(</span><span class=\"s2\">&quot;env.linear&quot;</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">w0</span><span class=\"p\">,</span> <span class=\"n\">b0</span><span class=\"p\">),</span> <span class=\"n\">out_sinfo</span><span class=\"o\">=</span><span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span>\n",
       "        <span class=\"n\">lv1</span> <span class=\"o\">=</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">call_tir</span><span class=\"p\">(</span><span class=\"s2\">&quot;env.relu&quot;</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">lv0</span><span class=\"p\">,),</span> <span class=\"n\">out_sinfo</span><span class=\"o\">=</span><span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span>\n",
       "        <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">call_tir</span><span class=\"p\">(</span><span class=\"s2\">&quot;env.linear&quot;</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">lv1</span><span class=\"p\">,</span> <span class=\"n\">w1</span><span class=\"p\">,</span> <span class=\"n\">b1</span><span class=\"p\">),</span> <span class=\"n\">out_sinfo</span><span class=\"o\">=</span><span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span>\n",
       "        <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">output</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">)</span>\n",
       "    <span class=\"k\">return</span> <span class=\"n\">out</span>\n",
       "    \n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{n+nd}{@R}\\PY{o}{.}\\PY{n}{function}\n",
       "\\PY{k}{def} \\PY{n+nf}{main}\\PY{p}{(}\\PY{n}{x}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{784}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{w0}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{784}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{b0}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{w1}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{b1}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "    \\PY{c+c1}{\\PYZsh{} block 0}\n",
       "    \\PY{k}{with} \\PY{n}{R}\\PY{o}{.}\\PY{n}{dataflow}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{lv0} \\PY{o}{=} \\PY{n}{R}\\PY{o}{.}\\PY{n}{call\\PYZus{}tir}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{env.linear}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{(}\\PY{n}{x}\\PY{p}{,} \\PY{n}{w0}\\PY{p}{,} \\PY{n}{b0}\\PY{p}{)}\\PY{p}{,} \\PY{n}{out\\PYZus{}sinfo}\\PY{o}{=}\\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
       "        \\PY{n}{lv1} \\PY{o}{=} \\PY{n}{R}\\PY{o}{.}\\PY{n}{call\\PYZus{}tir}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{env.relu}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{(}\\PY{n}{lv0}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{out\\PYZus{}sinfo}\\PY{o}{=}\\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
       "        \\PY{n}{out} \\PY{o}{=} \\PY{n}{R}\\PY{o}{.}\\PY{n}{call\\PYZus{}tir}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{env.linear}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{(}\\PY{n}{lv1}\\PY{p}{,} \\PY{n}{w1}\\PY{p}{,} \\PY{n}{b1}\\PY{p}{)}\\PY{p}{,} \\PY{n}{out\\PYZus{}sinfo}\\PY{o}{=}\\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
       "        \\PY{n}{R}\\PY{o}{.}\\PY{n}{output}\\PY{p}{(}\\PY{n}{out}\\PY{p}{)}\n",
       "    \\PY{k}{return} \\PY{n}{out}\n",
       "    \n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "@R.function\n",
       "def main(x: R.Tensor((1, 784), dtype=\"float32\"), w0: R.Tensor((128, 784), dtype=\"float32\"), b0: R.Tensor((128,), dtype=\"float32\"), w1: R.Tensor((10, 128), dtype=\"float32\"), b1: R.Tensor((10,), dtype=\"float32\")) -> R.Tensor((1, 10), dtype=\"float32\"):\n",
       "    # block 0\n",
       "    with R.dataflow():\n",
       "        lv0 = R.call_tir(\"env.linear\", (x, w0, b0), out_sinfo=R.Tensor((1, 128), dtype=\"float32\"))\n",
       "        lv1 = R.call_tir(\"env.relu\", (lv0,), out_sinfo=R.Tensor((1, 128), dtype=\"float32\"))\n",
       "        out = R.call_tir(\"env.linear\", (lv1, w1, b1), out_sinfo=R.Tensor((1, 10), dtype=\"float32\"))\n",
       "        R.output(out)\n",
       "    return out\n",
       "    "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.Code(MyModuleWithExternCall['main'].script(), language='python')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```pythoon\n",
    "R.call_tir(\"env.linear\", (x, w0, b0), relax.TensorStructInfo((1, 128), dtype='float32))\n",
    "```\n",
    "\"env.linear\"在模型执行期间的运行时函数 (runtime function) 的名称"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.1 注册运行时函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.register_func(\"env.linear\", override=True)\n",
    "def torch_linnear(x: tvm.nd.NDArray,\n",
    "                  w: tvm.nd.NDArray,\n",
    "                  b: tvm.nd.NDArray,\n",
    "                  out: tvm.nd.NDArray):\n",
    "    x_torch = torch.from_dlpack(x)\n",
    "    w_torch = torch.from_dlpack(w)\n",
    "    b_torch = torch.from_dlpack(b)\n",
    "    out_torch = torch.from_dlpack(out)\n",
    "    torch.mm(x_torch, w_torch.T, out=out_torch)\n",
    "    torch.add(out_torch, b_torch, out=out_torch)\n",
    "\n",
    "@tvm.register_func(\"env.relu\", override=True)\n",
    "def torch_relu(x: tvm.nd.NDArray,\n",
    "                out: tvm.nd.NDArray):\n",
    "    x_torch = torch.from_dlpack(x)\n",
    "    out_torch = torch.from_dlpack(out)\n",
    "    torch.maximum(x_torch, torch.Tensor([0.0]), out=out_torch)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from_dlpack 将 TVM NDArray 转换为 torch NDArray。 请注意，这是一个零拷贝转换，这意味着 Torch 阵列与 TVM NDArray 共享底层内存。 DLPack 是一种通用的交换标准，允许不同的框架交换 Tensor/NDArray 而无需参与数据复制。 from_dlpack API 由多个框架支持，是 Python 数组 API 标准的一部分"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2 Build and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModuleWithExternCall Prediction: Sandal\n"
     ]
    }
   ],
   "source": [
    "ex_env = relax.vm.build(MyModuleWithExternCall, target='llvm')\n",
    "vm = relax.VirtualMachine(ex_env, tvm.cpu())\n",
    "\n",
    "nd_res = vm['main'](data_nd,\n",
    "                    nd_params['w0'],\n",
    "                    nd_params['b0'],\n",
    "                    nd_params['w1'],\n",
    "                    nd_params['b1'])\n",
    "\n",
    "pred_kind = np.argmax(nd_res.numpy(), axis=1)\n",
    "print(\"MyModuleWithExternCall Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df7b789d6764113f3eb4ff8e192e7912fbf893c46539f75332048503ce5ba603"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
