{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorIR练习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm.script import tir as T\n",
    "import IPython\n",
    "from tvm.ir.module import IRModule"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5.1 TensorIR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1.1 逐位相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy\n",
    "a = np.arange(16).reshape(4, 4)\n",
    "b = np.arange(16, 0, -1).reshape(4, 4)\n",
    "c_np = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low-level numpy version\n",
    "def lnumpy_add(a: np.ndarray, b: np.ndarray, c: np.ndarray):\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            c[i, j] = a[i, j] + b[i, j]\n",
    "c_lnp = np.empty((4, 4), dtype=np.int64)\n",
    "lnumpy_add(a, b, c_lnp)\n",
    "np.testing.assert_equal(c_lnp, c_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorIR\n",
    "@tvm.script.ir_module\n",
    "class MyAdd():\n",
    "    @T.prim_func\n",
    "    def add(A: T.Buffer[(4, 4), 'int64'],\n",
    "            B: T.Buffer[(4, 4), 'int64'],\n",
    "            C: T.Buffer[(4, 4), 'int64']):\n",
    "        T.func_attr({'global_symbol': 'add', 'tir.noalias': True})\n",
    "        for i, j in T.grid(4, 4):\n",
    "            with T.block(\"C\"):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                C[vi, vj] = A[vi, vj] + B[vi, vj]\n",
    "\n",
    "rt_lib = tvm.build(MyAdd, target='llvm')\n",
    "a_tvm = tvm.nd.array(a)\n",
    "b_tvm = tvm.nd.array(b)\n",
    "c_tvm = tvm.nd.empty((4, 4), dtype='int64')\n",
    "rt_lib['add'](a_tvm, b_tvm, c_tvm)\n",
    "np.testing.assert_equal(c_tvm.numpy(), c_np)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1.2 广播加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  4,  4,  4],\n",
       "       [ 8,  8,  8,  8],\n",
       "       [12, 12, 12, 12],\n",
       "       [16, 16, 16, 16]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy\n",
    "a = np.arange(16).reshape(4, 4)\n",
    "b = np.arange(4, 0, -1).reshape(4)\n",
    "c_np = a + b\n",
    "c_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low-level numpy\n",
    "def lnumpy_b_add(a: np.ndarray, b: np.ndarray, c: np.ndarray):\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            c[i, j] = a[i, j] + b[j]\n",
    "\n",
    "c_lnp = np.empty((4, 4), dtype='int64')\n",
    "lnumpy_b_add(a, b, c_lnp)\n",
    "np.testing.assert_equal(c_lnp, c_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorIR\n",
    "@tvm.script.ir_module\n",
    "class MyBAdd():\n",
    "    @T.prim_func\n",
    "    def b_add(A: T.Buffer[(4, 4), 'int64'],\n",
    "              B: T.Buffer[(4), 'int64'],\n",
    "              C: T.Buffer[(4, 4), 'int64']):\n",
    "        T.func_attr({\"global_symbol\": \"b_add\", \"tir.noalias\": True})\n",
    "        for i, j in T.grid(4, 4):\n",
    "            with T.block(\"C\"):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                C[vi, vj] = A[vi, vj] + B[vj]\n",
    "\n",
    "rt_lib = tvm.build(MyBAdd, target='llvm')\n",
    "a_tvm = tvm.nd.array(a)\n",
    "b_tvm = tvm.nd.array(b)\n",
    "c_tvm = tvm.nd.empty((4, 4), dtype='int64')\n",
    "rt_lib['b_add'](a_tvm, b_tvm, c_tvm)\n",
    "np.testing.assert_equal(c_tvm.numpy(), c_np)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1.3 二维卷积"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Conv[b,k,i,j] = \\sum_{di,dj,q}{A[b,q,stride*i+di,strides*j+dj]*W[k,q,di,dj]}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, Ci, H, W, Co, K = 1, 1, 8, 8, 2, 3\n",
    "Out_H, Out_W = H - K + 1, W - K + 1\n",
    "data = np.arange(N*Ci*H*W).reshape(N,Ci,H,W)\n",
    "kernel = np.arange(K*K*Ci*Co).reshape(Co,Ci,K,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 474,  510,  546,  582,  618,  654],\n",
       "         [ 762,  798,  834,  870,  906,  942],\n",
       "         [1050, 1086, 1122, 1158, 1194, 1230],\n",
       "         [1338, 1374, 1410, 1446, 1482, 1518],\n",
       "         [1626, 1662, 1698, 1734, 1770, 1806],\n",
       "         [1914, 1950, 1986, 2022, 2058, 2094]],\n",
       "\n",
       "        [[1203, 1320, 1437, 1554, 1671, 1788],\n",
       "         [2139, 2256, 2373, 2490, 2607, 2724],\n",
       "         [3075, 3192, 3309, 3426, 3543, 3660],\n",
       "         [4011, 4128, 4245, 4362, 4479, 4596],\n",
       "         [4947, 5064, 5181, 5298, 5415, 5532],\n",
       "         [5883, 6000, 6117, 6234, 6351, 6468]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch version\n",
    "import torch\n",
    "\n",
    "data_torch = torch.Tensor(data)\n",
    "kernel_torch = torch.Tensor(kernel)\n",
    "conv_torch = torch.nn.functional.conv2d(data_torch, kernel_torch)\n",
    "conv_torch = conv_torch.numpy().astype(np.int64)\n",
    "conv_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0  1  2  3  4  5  6  7]\n",
      "   [ 8  9 10 11 12 13 14 15]\n",
      "   [16 17 18 19 20 21 22 23]\n",
      "   [24 25 26 27 28 29 30 31]\n",
      "   [32 33 34 35 36 37 38 39]\n",
      "   [40 41 42 43 44 45 46 47]\n",
      "   [48 49 50 51 52 53 54 55]\n",
      "   [56 57 58 59 60 61 62 63]]]]\n",
      "[[[[ 0  1  2]\n",
      "   [ 3  4  5]\n",
      "   [ 6  7  8]]]\n",
      "\n",
      "\n",
      " [[[ 9 10 11]\n",
      "   [12 13 14]\n",
      "   [15 16 17]]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tvm.nd.NDArray shape=(1, 2, 6, 6), cpu(0)>\n",
       "array([[[[              0,  94682335971344,  94682333359128,\n",
       "               3296526593,             128,             128],\n",
       "         [ 94682335293008,  94682333360336,  94682335982315,\n",
       "           94682335507832,               0,      4294967317],\n",
       "         [140517446610048,               0,               0,\n",
       "                        0,               0,  94682333826112],\n",
       "         [ 94682336148440,             257,              -8,\n",
       "                      449,  94682335759392,  94682335697648],\n",
       "         [ 94682335982441,               0,               0,\n",
       "                        3,  94682335507832,               0],\n",
       "         [     8589934614, 140517446610000,               0,\n",
       "                        0,  94682334779424,  94682334779424]],\n",
       "\n",
       "        [[ 94682333826112,  94682335053056,     77089865985,\n",
       "          140527034957823,             160,             128],\n",
       "         [ 94682336285152,  94682335234480,  94682336504459,\n",
       "           94682335507832,               0,      4294967317],\n",
       "         [140517446610048,               0,               0,\n",
       "                        0,               0,  94682333718336],\n",
       "         [ 94682335313400,      4076339457,             288,\n",
       "                      128,  94682335982288,  94682336504160],\n",
       "         [ 94682333926107,  94682335507832,               0,\n",
       "               4294967317, 140517446610048,               0],\n",
       "         [              0,               0,               0,\n",
       "           94682333846912,  94682335313592,      4074111233]]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TensorIR\n",
    "@tvm.script.ir_module\n",
    "class MyConv:\n",
    "    @T.prim_func\n",
    "    def conv(X: T.Buffer[(1, 1, 8, 8), 'int64'],\n",
    "             K: T.Buffer[(2, 1, 3, 3), 'int64'],\n",
    "             Y: T.Buffer[(1, 2, 6, 6), 'int64']):\n",
    "        T.func_attr({'global_symbol': 'conv', 'tir.noalias': True})\n",
    "        for n, co, h, w, ci, k1, k2 in T.grid(1, 2, 6, 6, 1, 3, 3):\n",
    "            with T.block(\"Y\"):\n",
    "                vn, vco, vh, vw, vci, vk1, vk2 = T.axis.remap(\"SSSSRRR\", [n, co, h, w, ci, k1, k2])\n",
    "                with T.init():\n",
    "                    Y[vn, vco, vh, vw] = T.int64(0)\n",
    "                Y[vn, vco, vh, vw] = Y[vn, vco, vh, vw] + X[vn, vci, vh + k1, vw + k2] * K[vco, vci, vk1, vk2]\n",
    "\n",
    "# IPython.display.Code(MyConv.script(), language='python')\n",
    "rt_lib = tvm.build(MyConv, target='llvm')\n",
    "data_tvm = tvm.nd.array(data)\n",
    "kernel_tvm = tvm.nd.array(kernel)\n",
    "print(data_tvm)\n",
    "print(kernel_tvm)\n",
    "conv_tvm = tvm.nd.empty((N, Co, Out_H, Out_W), dtype='int64')\n",
    "rt_lib['conv'](data_tvm, kernel_tvm, conv_tvm)\n",
    "conv_tvm\n",
    "# np.testing.assert_allclose(conv_tvm.numpy(), conv_torch, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df7b789d6764113f3eb4ff8e192e7912fbf893c46539f75332048503ce5ba603"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
