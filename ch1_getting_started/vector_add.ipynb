{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53c4dcac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ch1_getting_starting: vector_add'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"ch1_getting_starting: vector_add\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82ac3fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"import torch\" success...\n"
     ]
    }
   ],
   "source": [
    "# %load vector_add.py\n",
    "# improt package\n",
    "import tvm\n",
    "from tvm import te # te stands for tensor expression\n",
    "import time\n",
    "import timeit\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "try:\n",
    "    import torch \n",
    "    print(\"\\\"import torch\\\" success...\")\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48518576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implemention with numpy\n",
    "def get_abc(shape, constructor = None):\n",
    "    \"\"\" return random a, b and empty c with the same shape\n",
    "    \"\"\"\n",
    "    np.random.seed(0)\n",
    "    a = np.random.normal(size = shape).astype(np.float32)\n",
    "    b = np.random.normal(size = shape).astype(np.float32)\n",
    "    c = np.empty(shape = shape, dtype = np.float32)\n",
    "    if constructor is not None:\n",
    "        a, b, c = [constructor(i) for i in (a, b, c)]\n",
    "    return a, b, c\n",
    "\n",
    "n = 100\n",
    "a, b, c = get_abc(n, None)\n",
    "c = a + b\n",
    "def vector_add_normal(n, a, b):\n",
    "    d = np.empty_like(a)\n",
    "    for i in range(n):\n",
    "        d[i] = a[i] + b[i]\n",
    "    return d\n",
    "d = vector_add_normal(n, a, b)\n",
    "np.testing.assert_equal(c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e25dbdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tvm.te.tensor.Tensor'> <class 'tvm.te.tensor.Tensor'>\n",
      "float32 [100]\n",
      "<class 'tvm.te.tensor.PlaceholderOp'> <class 'tvm.te.tensor.ComputeOp'>\n",
      "<class 'tvm.te.tensor.Operation'>\n",
      "<class 'tvm.te.schedule.Schedule'> <class 'tvm.te.schedule.Stage'>\n",
      "@main = primfn(a_1: handle, b_1: handle, c_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {a: Buffer(a_2: Pointer(float32), float32, [100], []),\n",
      "             b: Buffer(b_2: Pointer(float32), float32, [100], []),\n",
      "             c: Buffer(c_2: Pointer(float32), float32, [100], [])}\n",
      "  buffer_map = {a_1: a, b_1: b, c_1: c}\n",
      "  preflattened_buffer_map = {a_1: a_3: Buffer(a_2, float32, [100], []), b_1: b_3: Buffer(b_2, float32, [100], []), c_1: c_3: Buffer(c_2, float32, [100], [])} {\n",
      "  for (i: int32, 0, 100) {\n",
      "    c[i] = (a[i] + b[i])\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defining the tvm computation\n",
    "def vector_add(n):\n",
    "    \"\"\"TVM expressoion for vector add\"\"\"\n",
    "    A = te.placeholder((n,), name = 'a')\n",
    "    B = te.placeholder((n,), name = 'b')\n",
    "    C = te.compute(A.shape, lambda i : A[i] + B[i], name = 'c')\n",
    "    return A, B, C\n",
    "\n",
    "A, B, C = vector_add(n)\n",
    "print(type(A), type(C))\n",
    "print(A.dtype,  A.shape)\n",
    "print(type(A.op), type(C.op))\n",
    "print(A.op.__class__.__bases__[0])\n",
    "\n",
    "# create a schedule: execute plan\n",
    "s = te.create_schedule(C.op)\n",
    "print(type(s), type(s[C.op]))\n",
    "print(tvm.lower(s, [A, B, C], simple_mode = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba366d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tvm.driver.build_module.OperatorModule'>\n"
     ]
    }
   ],
   "source": [
    "# compilation and execution\n",
    "mod = tvm.build(s, [A, B, C])\n",
    "print(type(mod))\n",
    "\"\"\" tvm.ndarray.NDArray ---> np.ndarray (.asnumpy())\n",
    "    np.ndarray ---> tvm.ndarray.NDArray (tvm.nd.array())\n",
    "\"\"\"\n",
    "a, b, c = get_abc(n, tvm.nd.array)\n",
    "mod(a, b, c)\n",
    "np.testing.assert_equal(a.asnumpy() + b.asnumpy(), c.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c92a1cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  1: TVMFuncCall\n",
      "  0: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n",
      "  File \"/staff/qiaoliang/ACSA科研项目/TVM/tvm/src/runtime/library_module.cc\", line 80\n",
      "TVMError: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "\n",
      "  Check failed: ret == 0 (-1 vs. 0) : Assert fail: (100 == int32(arg.a.shape[0])), Argument arg.a.shape[0] has an unsatisfied constraint: (100 == int32(arg.a.shape[0]))\n"
     ]
    }
   ],
   "source": [
    "# argument constraints-1\n",
    "try:\n",
    "    \"\"\" TVM will check if the input shapes satisfy this specification.\n",
    "        A/B/C's shape is 100, a/b/c's shape is 200. shape not satisfy!\n",
    "    \"\"\"\n",
    "    a, b, c = get_abc(200, tvm.nd.array)\n",
    "    mod(a, b, c)\n",
    "except tvm.TVMError as e:\n",
    "    print(e)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3e25671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  1: TVMFuncCall\n",
      "  0: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n",
      "  File \"/staff/qiaoliang/ACSA科研项目/TVM/tvm/src/runtime/library_module.cc\", line 80\n",
      "TVMError: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "\n",
      "  Check failed: ret == 0 (-1 vs. 0) : Assert fail: (((tir.tvm_struct_get(arg.a, 0, 5) == (uint8)2) && (tir.tvm_struct_get(arg.a, 0, 6) == (uint8)32)) && (tir.tvm_struct_get(arg.a, 0, 7) == (uint16)1)), arg.a.dtype is expected to be float32\n"
     ]
    }
   ],
   "source": [
    "# argument constraints-1\n",
    "try:\n",
    "    \"\"\" An error will appear if input with a different data type.\n",
    "        A/B/C's dtype is float32, a/b/c's dtype is float64. dtype not satisfy!\n",
    "    \"\"\"\n",
    "    a, b, c = get_abc(100, tvm.nd.array)\n",
    "    a, b, c = [tvm.nd.array(i.asnumpy().astype(np.float64)) for i in (a, b, c)]\n",
    "    mod(a, b, c)\n",
    "except tvm.TVMError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f582e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving and loading a module\n",
    "mod_fname = 'vector-add.tar'\n",
    "mod.export_library(mod_fname)\n",
    "loaded_mod = tvm.runtime.load_module(mod_fname)\n",
    "\n",
    "# verify the results\n",
    "a, b, c = get_abc(100, tvm.nd.array)\n",
    "loaded_mod(a, b, c)\n",
    "np.testing.assert_equal(a.asnumpy() + b.asnumpy(), c.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adf0e2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Implementing an operator using TVM has 3 steps:\\n        1.Computation: Declare the computation by specifying input and output shapes and how each output element is computed.\\n        2.Schedule: Create a schedule to fully utilize the machine resources.\\n        3.Compile: Compile to the hardware target.\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary\n",
    "\"\"\"\n",
    "    Implementing an operator using TVM has 3 steps:\n",
    "        1.Computation: Declare the computation by specifying input and output shapes and how each output element is computed.\n",
    "        2.Schedule: Create a schedule to fully utilize the machine resources.\n",
    "        3.Compile: Compile to the hardware target.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
