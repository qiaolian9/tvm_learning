{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de4e3490",
   "metadata": {},
   "source": [
    "# Compute definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ead11317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/staff/qiaoliang/ACSA科研项目/tvm_learning/d2ltvm/d2ltvm.py:153: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if conv_type is 'depthwise':\n",
      "/staff/qiaoliang/ACSA科研项目/tvm_learning/d2ltvm/d2ltvm.py:184: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  PaddedX = padding(X, ph, pw) if ph | pw is not 0 else X\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successd...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import d2ltvm\n",
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad96def7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2ltvm import padding, conv_out_size\n",
    "def depthwise_conv(ic, nh, nw, kh, kw, ph=0, pw=0, sh=1, sw=1):\n",
    "    \"\"\" Convolution\n",
    "        ic : number of channels for both input and output\n",
    "        nh, nw : input width and height\n",
    "        kh, kw : kernel width and height\n",
    "        ph, pw : height and width padding sizes, default 0\n",
    "        sh, sw : height and width strides, default 1\n",
    "    \"\"\"\n",
    "    # reduction axis\n",
    "    rkh = te.reduce_axis((0, kh), name='rkh')\n",
    "    rkw = te.reduce_axis((0, kw), name='rkw')\n",
    "    # output height and weights\n",
    "    oh = conv_out_size(nh, kh, ph, sh)\n",
    "    ow = conv_out_size(nw, kw, pw, sw)\n",
    "    # pad X and then compute Y\n",
    "    X = te.placeholder((ic, nh, nw), name='X')\n",
    "    K = te.placeholder((ic, 1, kh, kw), name='Y')\n",
    "    PaddedX = padding(X, ph, pw) if (ph | pw) != 0 else X\n",
    "    Y = te.compute((ic, oh, ow),\n",
    "                  lambda c, i, j: te.sum(PaddedX[c, i * sh + rkh, j * sw + rkw] * K[c, 0, rkh, rkw],\n",
    "                    axis=[rkh, rkw]), name='Y')\n",
    "    return X, K, Y, PaddedX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce29603a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@main = primfn(X_1: handle, Y_2: handle, Y_3: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {X: Buffer(X_2: Pointer(float32), float32, [36864], []),\n",
      "             Y: Buffer(Y_4: Pointer(float32), float32, [2304], []),\n",
      "             Y_1: Buffer(Y_5: Pointer(float32), float32, [36864], [])}\n",
      "  buffer_map = {X_1: X, Y_2: Y, Y_3: Y_1}\n",
      "  preflattened_buffer_map = {X_1: X_3: Buffer(X_2, float32, [256, 12, 12], []), Y_2: Y_6: Buffer(Y_4, float32, [256, 1, 3, 3], []), Y_3: Y_7: Buffer(Y_5, float32, [256, 12, 12], [])} {\n",
      "  allocate(PaddedX: Pointer(global float32), float32, [50176]), storage_scope = global {\n",
      "    for (i0: int32, 0, 256) {\n",
      "      for (i1: int32, 0, 14) {\n",
      "        for (i2: int32, 0, 14) {\n",
      "          PaddedX_1: Buffer(PaddedX, float32, [50176], [])[(((i0*196) + (i1*14)) + i2)] = @tir.if_then_else(((((i1 < 1) || (13 <= i1)) || (i2 < 1)) || (13 <= i2)), 0f32, X[((((i0*144) + (i1*12)) + i2) - 13)], dtype=float32)\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    for (c: int32, 0, 256) {\n",
      "      for (i: int32, 0, 12) {\n",
      "        for (j: int32, 0, 12) {\n",
      "          Y_1[(((c*144) + (i*12)) + j)] = 0f32\n",
      "          for (rkh: int32, 0, 3) {\n",
      "            for (rkw: int32, 0, 3) {\n",
      "              let cse_var_1: int32 = (((c*144) + (i*12)) + j)\n",
      "              Y_1[cse_var_1] = (Y_1[cse_var_1] + (PaddedX_1[(((((c*196) + (i*14)) + (rkh*14)) + j) + rkw)]*Y[(((c*9) + (rkh*3)) + rkw)]))\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ic, n, k, p, s = 256, 12, 3, 1, 1\n",
    "X, K, Y, _ = depthwise_conv(ic, n, n, k, k, p, p, s, s)\n",
    "sch = te.create_schedule(Y.op)\n",
    "print(tvm.lower(sch, [X, K, Y], simple_mode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f463bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = tvm.build(sch, [X, K, Y])\n",
    "data, weight, out = d2ltvm.get_conv_data(ic, ic, n, k, p, s, tvm.nd.array, 'depthwise')\n",
    "mod(data, weight, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b621356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def get_conv_data_torch(oc, ic, n, k, p, s, ctx='cpu', conv_type='direct'):\n",
    "    device = torch.device(ctx)\n",
    "    data, weight, _ = d2ltvm.get_conv_data(oc, ic, n, k, p, s, constructor=lambda x: torch.tensor(x, device=device), conv_type='depthwise')\n",
    "    data = data[None, ...]\n",
    "    bias = torch.zeros(oc, device=device)\n",
    "    return data, weight, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcd7a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depthwise_conv_torch(data, weight, bias, p, s):\n",
    "    return torch.nn.functional.conv2d(data, weight, bias, s, p, groups=data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4b62810",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1, weight1, bias1 = get_conv_data_torch(ic, ic, n, k, p, s, conv_type='depthwise')\n",
    "out1 = depthwise_conv_torch(data1, weight1, bias1, p, s)\n",
    "np.testing.assert_allclose(out.asnumpy(), out1[0].numpy(), atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1bd374",
   "metadata": {},
   "source": [
    "# Summary\n",
    "1.Depthwise convolution, together with pointwise convolution, can save a lot of computation and memory compared to normal 2-D convolution \\\n",
    "2.Depthwise convolution takes kernels in 3-D, while normal 2-D convolution takes kernels in 4-D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
