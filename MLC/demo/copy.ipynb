{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import tvm\n",
    "from MLC import mlc\n",
    "from tvm import te, relax, IRModule\n",
    "from tvm.script import relax as R\n",
    "from tvm.script import tir as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Demo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w = nn.Parameter(torch.rand((900, 128)))\n",
    "        self.b = nn.Parameter(torch.rand((128,)))\n",
    "        self.conv2d = nn.Conv2d(1, 1, 3, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv2d(x)\n",
    "        x = torch.relu(x)\n",
    "        x = x.view([1, -1])\n",
    "        x = torch.matmul(x, self.w)\n",
    "        x = torch.add(x, self.b)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DemoRelax = mlc.from_fx(Demo(), [(1, 1, 32, 32)])\n",
    "# DemoRelax.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DemoFused = mlc.FuseDenseAddPass()(DemoRelax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DemoModelTIR = mlc.LowerToTensorIRPass()(DemoFused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DemoModelFinal = relax.transform.FuseTIR()(DemoModelTIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.369782421875\n"
     ]
    }
   ],
   "source": [
    "hw = 32\n",
    "nrepeat = 10000\n",
    "x = np.random.rand(1, 1, hw, hw).astype('float32')\n",
    "x_torch_cuda = torch.from_numpy(x)\n",
    "demo_cuda = Demo()\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "start.record()\n",
    "for _ in range(nrepeat):\n",
    "    demo_cuda(x_torch_cuda)\n",
    "end.record()\n",
    "\n",
    "print(start.elapsed_time(end) / nrepeat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch ---> IRModule"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: TorchFX GraphModule\n",
    "\n",
    "nn.Module ---> torch.fx.graph_module.GraphModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.fx.graph_module.GraphModule.__new__.<locals>.GraphModuleImpl"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TorchFx Graphmodule\n",
    "model = Demo()\n",
    "fx_module = fx.symbolic_trace(model)\n",
    "type(fx_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name    target                                                     args             kwargs\n",
      "-------------  ------  ---------------------------------------------------------  ---------------  --------\n",
      "placeholder    x       x                                                          ()               {}\n",
      "call_module    conv2d  conv2d                                                     (x,)             {}\n",
      "call_function  relu    <built-in method relu of type object at 0x7f4e31692ec0>    (conv2d,)        {}\n",
      "call_method    view    view                                                       (relu, [1, -1])  {}\n",
      "get_attr       w       w                                                          ()               {}\n",
      "call_function  matmul  <built-in method matmul of type object at 0x7f4e31692ec0>  (view, w)        {}\n",
      "get_attr       b       b                                                          ()               {}\n",
      "call_function  add     <built-in method add of type object at 0x7f4e31692ec0>     (matmul, b)      {}\n",
      "call_module    relu_1  relu                                                       (add,)           {}\n",
      "call_module    linear  linear                                                     (relu_1,)        {}\n",
      "output         output  output                                                     (linear,)        {}\n"
     ]
    }
   ],
   "source": [
    "fx_module.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': Demo(\n",
       "   (conv2d): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "   (relu): ReLU()\n",
       "   (linear): Linear(in_features=128, out_features=10, bias=True)\n",
       " ),\n",
       " 'conv2d': Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1)),\n",
       " 'relu': ReLU(),\n",
       " 'linear': Linear(in_features=128, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(fx_module.named_modules())\n",
    "# for i in fx_module.graph.nodes:\n",
    "#     print(i.op)\n",
    "# getattr(fx_module, 'linear').bias\n",
    "# type(relax.Var('x', R.Tensor((1,10))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: 构造映射函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_params(param: nn.Parameter):\n",
    "    return relax.const(param.data.cpu().numpy(), dtype='float32')\n",
    "\n",
    "def fetch_attr(fx_mod, target: str):\n",
    "    # 获取mod属性\n",
    "    target_atoms = target.split('.')\n",
    "    attr_itr = fx_mod\n",
    "    for i, atom in enumerate(target_atoms):\n",
    "        if not hasattr(attr_itr, atom):\n",
    "            raise RuntimeError(f\"Node referenced nonexistant target {'.'.join(target_atoms[:i])}\")\n",
    "        attr_itr = getattr(attr_itr, atom)\n",
    "    return attr_itr\n",
    "\n",
    "def from_fx(fx_module: torch.fx.GraphModule, input_shapes, call_map_function, call_map_module, call_map_method):\n",
    "    ''' 根据映射将torchgraph ---> relax function\n",
    "        1. function 参数直接来自于node_map\n",
    "        2. module 带参数+计算\n",
    "        \n",
    "        example:\n",
    "        with bb.function('main'):\n",
    "            with bb.dataflow():\n",
    "                (var = bb.emt_)\n",
    "                bb.emit_output()\n",
    "        bb.emit_func_output(fn_output, fn_inputs)\n",
    "    '''\n",
    "    input_index = 0\n",
    "    node_map = {}\n",
    "    named_modules = dict(fx_module.named_modules())\n",
    "\n",
    "    bb = relax.BlockBuilder()\n",
    "    fn_inputs = []\n",
    "    fn_output = None\n",
    "    with bb.function('main'):\n",
    "        with bb.dataflow():\n",
    "            for node in fx_module.graph.nodes:\n",
    "                if node.op == 'placeholder':\n",
    "                    input_shape = input_shapes[input_index]\n",
    "                    input_index = input_index + 1\n",
    "                    fn_input = relax.Var(node.target, R.Tensor(input_shape, 'float32'))\n",
    "                    fn_inputs.append(fn_input)\n",
    "                    node_map[node] = fn_input\n",
    "                elif node.op == 'get_attr':\n",
    "                    node_map[node] = map_params(fetch_attr(fx_module, node.target))\n",
    "                elif node.op == 'call_function':\n",
    "                    node_map[node] = call_map_function[node.target](bb, node_map, node)\n",
    "                # --------------------- add call_method ------------------------#\n",
    "                elif node.op == 'call_method':\n",
    "                    node_map[node] = call_map_method[node.target](bb, node_map, node)\n",
    "                # --------------------------------------------------------------#\n",
    "                elif node.op == 'call_module':\n",
    "                    nn_module = named_modules[node.target]\n",
    "                    # node_map[node] = call_map_module[nn_module](bb, node_map, node, nn_module)\n",
    "                    node_map[node] = call_map_module[type(nn_module)](bb, node_map, node, nn_module)\n",
    "                elif node.op == 'output':\n",
    "                    output = node_map[node.args[0]]\n",
    "                    if fn_output is not None:\n",
    "                        raise Warning(\"error\")\n",
    "                    fn_output = bb.emit_output(output)\n",
    "        bb.emit_func_output(fn_output, fn_inputs)\n",
    "    return bb.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_function\n",
    "def map_matmul(bb: relax.BlockBuilder, node_map, node):\n",
    "    x = node_map[node.args[0]]\n",
    "    w = node_map[node.args[1]]\n",
    "    return bb.emit(relax.op.matmul(x, w))\n",
    "\n",
    "def map_relu(bb: relax.BlockBuilder, node_map, node):\n",
    "    x = node_map[node.args[0]]\n",
    "    return bb.emit(relax.op.nn.relu(x))\n",
    "\n",
    "def map_add(bb: relax.BlockBuilder, node_map, node):\n",
    "    x = node_map[node.args[0]]\n",
    "    b = node_map[node.args[1]]\n",
    "    return bb.emit(relax.op.add(x, b))\n",
    "\n",
    "# call_module\n",
    "def map_nn_relu(bb: relax.BlockBuilder, node_map, node, nn_module):\n",
    "    return bb.emit(relax.op.nn.relu(node_map[node.args[0]]))\n",
    "\n",
    "def map_nn_linear(bb: relax.BlockBuilder, node_map, node, nn_module):\n",
    "    x = node_map[node.args[0]]\n",
    "    w = map_params(nn_module.weight)\n",
    "    bias = map_params(nn_module.bias)\n",
    "    return bb.emit(relax.op.linear(x, w, bias))\n",
    "\n",
    "def map_nn_conv2d(bb: relax.BlockBuilder, node_map, node, nn_module):\n",
    "    x = node_map[node.args[0]]\n",
    "    kernel = map_params(nn_module.weight)\n",
    "    bias = None\n",
    "    if nn_module.bias is not None:\n",
    "        bias = map_params(nn_module.bias)\n",
    "    stride = nn_module.stride\n",
    "    conv_out = bb.emit(relax.op.nn.conv2d(x, kernel, stride))\n",
    "    if not bias:\n",
    "        return bb.emit(relax.op.add(conv_out, bias))\n",
    "    return conv_out\n",
    "\n",
    "# call_method\n",
    "def map_view(bb: relax.BlockBuilder, node_map, node):\n",
    "    x = node_map[node.args[0]]\n",
    "    shape = node.args[1]\n",
    "    return bb.emit(relax.op.reshape(x, shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_map_function = {\n",
    "    torch.matmul: map_matmul,\n",
    "    torch.relu: map_relu,\n",
    "    torch.add: map_add\n",
    "}\n",
    "\n",
    "call_map_module = {\n",
    "    torch.nn.Conv2d: map_nn_conv2d,\n",
    "    torch.nn.ReLU: map_nn_relu,\n",
    "    torch.nn.Linear: map_nn_linear\n",
    "}\n",
    "\n",
    "call_map_method = {\n",
    "    'view': map_view\n",
    "}\n",
    "\n",
    "DemoModel = from_fx(fx_module, [(1, 1, hw, hw)], call_map_function, call_map_module, call_map_method)\n",
    "\n",
    "# DemoModel.show(show_meta=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tvm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/staff/qiaoliang/ACSA科研项目/tvm_learning/MLC/demo/copy.ipynb 单元格 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsnode2/staff/qiaoliang/ACSA%E7%A7%91%E7%A0%94%E9%A1%B9%E7%9B%AE/tvm_learning/MLC/demo/copy.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m tvm\u001b[39m.\u001b[39mir\u001b[39m.\u001b[39massert_structural_equal(DemoRelax, DemoModel)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tvm' is not defined"
     ]
    }
   ],
   "source": [
    "tvm.ir.assert_structural_equal(DemoRelax, DemoModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I.GlobalVar(\"main\") # from tvm.script import relax as R\n",
      "\n",
      "@R.function\n",
      "def main(x: R.Tensor((1, 1, 32, 32), dtype=\"float32\")) -> R.Tensor((1, 10), dtype=\"float32\"):\n",
      "    with R.dataflow():\n",
      "        lv: R.Tensor((1, 1, 30, 30), dtype=\"float32\") = R.nn.conv2d(x, metadata[\"relax.expr.Constant\"][0], strides=[1, 1], padding=[0, 0, 0, 0], dilation=[1, 1], groups=1, data_layout=\"NCHW\", kernel_layout=\"OIHW\", out_layout=\"NCHW\", out_dtype=\"void\")\n",
      "        lv1: R.Tensor((1, 1, 30, 30), dtype=\"float32\") = R.nn.relu(lv)\n",
      "        lv2: R.Tensor((1, 900), dtype=\"float32\") = R.reshape(lv1, (1, 900))\n",
      "        lv3: R.Tensor((1, 128), dtype=\"float32\") = R.matmul(lv2, metadata[\"relax.expr.Constant\"][1], out_dtype=\"void\")\n",
      "        lv4: R.Tensor((1, 128), dtype=\"float32\") = R.add(lv3, metadata[\"relax.expr.Constant\"][2])\n",
      "        lv5: R.Tensor((1, 128), dtype=\"float32\") = R.nn.relu(lv4)\n",
      "        lv6: R.Tensor((128, 10), dtype=\"float32\") = R.permute_dims(metadata[\"relax.expr.Constant\"][3], axes=None)\n",
      "        lv7: R.Tensor((1, 10), dtype=\"float32\") = R.matmul(lv5, lv6, out_dtype=\"void\")\n",
      "        lv8: R.Tensor((1, 10), dtype=\"float32\") = R.add(lv7, metadata[\"relax.expr.Constant\"][4])\n",
      "        gv: R.Tensor((1, 10), dtype=\"float32\") = lv8\n",
      "        R.output(gv)\n",
      "    return gv\n",
      "\n",
      "# Metadata omitted. Use show_meta=True in script() method to show it. <class 'tvm.relax.expr.Function'>\n"
     ]
    }
   ],
   "source": [
    "for i, func in DemoModel.functions.items():\n",
    "    print(i, func, type(func))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: 图优化\n",
    "\n",
    "eg: 融合matmul & add算子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/staff/qiaoliang/anaconda3/envs/MLC/lib/python3.8/site-packages/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
      "To print formatted TVM script, please install the formatter 'Black':\n",
      "/staff/qiaoliang/anaconda3/envs/MLC/bin/python -m pip install \"black==22.3.0\" --upgrade --user\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">32</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">30</span>, <span style=\"color: #008000\">30</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>conv2d(x, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>], strides<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], padding<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>], dilation<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            lv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">30</span>, <span style=\"color: #008000\">30</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>relu(lv)\n",
       "            lv2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">900</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(lv1, (<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">900</span>))\n",
       "            lv4: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> fused_dense_add0(lv2, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">1</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">2</span>])\n",
       "            lv5: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>relu(lv4)\n",
       "            lv8: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> fused_dense_add1(lv5, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">3</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">4</span>])\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv8\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">fused_dense_add0</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">900</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), w: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">900</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), b: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        R<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;Primitive&quot;</span>: <span style=\"color: #008000\">1</span>})\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>matmul(x, w, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            lv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(lv, b)\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv1\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">fused_dense_add1</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), w: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), b: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        R<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;Primitive&quot;</span>: <span style=\"color: #008000\">1</span>})\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(w, axes<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">None</span>)\n",
       "            lv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>matmul(x, lv, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            lv2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(lv1, b)\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv2\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "\n",
       "<span style=\"color: #007979; font-style: italic\"># Metadata omitted. Use show_meta=True in script() method to show it.</span>\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。请查看单元格中的代码，以确定故障的可能原因。有关详细信息，请单击 <a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>。有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "def create_fuse_dense_add(call: relax.Call, value: relax.Call, value_pre=None, fn_name=None):\n",
    "    b = call.args[1]\n",
    "    x = value.args[0]\n",
    "    w = value.args[1]\n",
    "    if value_pre is not None:\n",
    "        w = value_pre.args[0]\n",
    "\n",
    "    params_x = relax.Var('x', x.struct_info)\n",
    "    params_w = relax.Var('w', w.struct_info)\n",
    "    params_b = relax.Var('b', b.struct_info)\n",
    "\n",
    "    bb = relax.BlockBuilder()\n",
    "    with bb.function(fn_name, [params_x, params_w, params_b]):\n",
    "        with bb.dataflow():\n",
    "            if value_pre is not None:\n",
    "                lv0 = bb.emit(relax.op.linear(params_x, params_w))\n",
    "            else:\n",
    "                lv0 = bb.emit(relax.op.matmul(params_x, params_w))\n",
    "            \n",
    "            gv = bb.emit_output(bb.emit(relax.op.add(lv0, params_b)))\n",
    "        bb.emit_func_output(gv)\n",
    "    \n",
    "    fused_fn = bb.get()[fn_name].with_attr(\"Primitive\", 1)\n",
    "    return fused_fn, x, w, b\n",
    "\n",
    "@relax.expr_functor.mutator\n",
    "class DenseAddFusor(relax.PyExprMutator):\n",
    "    def __init__(self, mod: IRModule) -> None:\n",
    "        super().__init__()\n",
    "        self.mod_ = mod\n",
    "        # cache pre-defined ops\n",
    "        # permute -> matmul -> add\n",
    "        self.add_op = tvm.ir.Op.get(\"relax.add\")\n",
    "        self.permute_op = tvm.ir.Op.get(\"relax.permute_dims\")\n",
    "        self.matmul_op = tvm.ir.Op.get(\"relax.matmul\")\n",
    "        self.counter = 0\n",
    "\n",
    "    def transform(self) -> IRModule:\n",
    "        for global_var, func in self.mod_.functions.items():\n",
    "            if not isinstance(func, relax.Function):\n",
    "                continue\n",
    "            # avoid already fused primitive functions\n",
    "            if func.attrs is not None and \"Primitive\" in func.attrs.keys() and func.attrs[\"Primitive\"] != 0:\n",
    "                continue\n",
    "            updated_func = self.visit_expr(func)\n",
    "            updated_func = relax.analysis.remove_all_unused(updated_func)\n",
    "            self.builder_.update_func(global_var, updated_func)\n",
    "\n",
    "        return self.builder_.get()\n",
    "\n",
    "    def visit_call_(self, call):\n",
    "        call = self.visit_expr_post_order(call)\n",
    "        \n",
    "        def match_call(node, op):\n",
    "            if not isinstance(node, relax.Call):\n",
    "                return False\n",
    "            return node.op == op\n",
    "\n",
    "        # pattern match dense => add\n",
    "        if not match_call(call, self.add_op):\n",
    "            return call\n",
    "\n",
    "        value = self.lookup_binding(call.args[0])\n",
    "        if value is None:\n",
    "            return call\n",
    "\n",
    "        if not match_call(value, self.matmul_op):\n",
    "            return call\n",
    "        \n",
    "        fn_name = \"fused_dense_add%d\" % (self.counter)\n",
    "        self.counter += 1\n",
    "        if type(value.args[1]) == tvm.relax.expr.Constant:\n",
    "            fused_fn, x, w, b= create_fuse_dense_add(call, value, fn_name=fn_name)\n",
    "        else:\n",
    "            value_1 = self.lookup_binding(value.args[1])\n",
    "            if not match_call(value_1, self.permute_op):\n",
    "                fused_fn, x, w, b = create_fuse_dense_add(call, value, fn_name=fn_name)\n",
    "            else:\n",
    "                fused_fn, x, w, b = create_fuse_dense_add(call, value, value_1, fn_name)\n",
    "        # x = value.args[0]\n",
    "        # w = value_1.args[0]\n",
    "        # b = call.args[1]\n",
    "\n",
    "        # # construct a new fused primitive function\n",
    "        # param_x = relax.Var(\"x\", x.struct_info)\n",
    "        # param_w = relax.Var(\"w\", w.struct_info)\n",
    "        # param_b = relax.Var(\"b\", b.struct_info)\n",
    "\n",
    "        # bb = relax.BlockBuilder()\n",
    "\n",
    "        # fn_name = \"fused_dense_add%d\" % (self.counter)\n",
    "        # self.counter += 1\n",
    "        # with bb.function(fn_name, [param_x, param_w, param_b]):\n",
    "        #     with bb.dataflow():\n",
    "        #         lv0 = bb.emit(relax.op.linear(param_x, param_w))\n",
    "        #         gv = bb.emit_output(relax.op.add(lv0, param_b))\n",
    "        #     bb.emit_func_output(gv)\n",
    "\n",
    "        # # Add Primitive attribute to the fused funtions\n",
    "        # fused_fn = bb.get()[fn_name].with_attr(\"Primitive\", 1)\n",
    "        global_var = self.builder_.add_func(fused_fn, fn_name)\n",
    "\n",
    "        # construct call into the fused function\n",
    "        return relax.Call(global_var, [x, w, b], None, None)\n",
    "\n",
    "@tvm.ir.transform.module_pass(opt_level=2, name=\"DeseAddFuse\")\n",
    "class FuseDenseAddPass:\n",
    "    \"\"\"The wrapper for the LowerTensorIR pass.\"\"\"\n",
    "    def transform_module(self, mod, ctx):\n",
    "        return DenseAddFusor(mod).transform()\n",
    "\n",
    "\n",
    "DemoFused = FuseDenseAddPass()(DemoModel)\n",
    "DemoFused.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: 映射到TensorIR Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/staff/qiaoliang/anaconda3/envs/MLC/lib/python3.8/site-packages/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
      "To print formatted TVM script, please install the formatter 'Black':\n",
      "/staff/qiaoliang/anaconda3/envs/MLC/bin/python -m pip install \"black==22.3.0\" --upgrade --user\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">32</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(conv2d, (x, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">30</span>, <span style=\"color: #008000\">30</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(relu, (lv,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">30</span>, <span style=\"color: #008000\">30</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(reshape, (lv1,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">900</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv4: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> fused_dense_add0(lv2, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">1</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">2</span>])\n",
       "            lv5 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(relu1, (lv4,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv8: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> fused_dense_add1(lv5, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">3</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">4</span>])\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv8\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">add</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>),), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_add: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
       "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_ax0, v_ax1], rxplaceholder_1[v_ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_add[v_ax0, v_ax1])\n",
       "                T_add[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> rxplaceholder[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder_1[v_ax1]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">add1</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>),), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_add: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
       "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_ax0, v_ax1], rxplaceholder_1[v_ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_add[v_ax0, v_ax1])\n",
       "                T_add[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> rxplaceholder[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder_1[v_ax1]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">conv2d</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), conv2d_nchw: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        pad_temp <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>)))\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2, i3 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;pad_temp&quot;</span>):\n",
       "                v_i0, v_i1, v_i2, v_i3 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSS&quot;</span>, [i0, i1, i2, i3])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_i0, v_i1, v_i2, v_i3])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(pad_temp[v_i0, v_i1, v_i2, v_i3])\n",
       "                pad_temp[v_i0, v_i1, v_i2, v_i3] <span style=\"color: #AA22FF; font-weight: bold\">=</span> rxplaceholder[v_i0, v_i1, v_i2, v_i3]\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> nn, ff, yy, xx, rc, ry, rx <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;conv2d_nchw&quot;</span>):\n",
       "                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSSRRR&quot;</span>, [nn, ff, yy, xx, rc, ry, rx])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(pad_temp[v_nn, v_rc, v_yy <span style=\"color: #AA22FF; font-weight: bold\">+</span> v_ry, v_xx <span style=\"color: #AA22FF; font-weight: bold\">+</span> v_rx], rxplaceholder_1[v_ff, v_rc, v_ry, v_rx])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(conv2d_nchw[v_nn, v_ff, v_yy, v_xx])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    conv2d_nchw[v_nn, v_ff, v_yy, v_xx] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                conv2d_nchw[v_nn, v_ff, v_yy, v_xx] <span style=\"color: #AA22FF; font-weight: bold\">=</span> conv2d_nchw[v_nn, v_ff, v_yy, v_xx] <span style=\"color: #AA22FF; font-weight: bold\">+</span> pad_temp[v_nn, v_rc, v_yy <span style=\"color: #AA22FF; font-weight: bold\">+</span> v_ry, v_xx <span style=\"color: #AA22FF; font-weight: bold\">+</span> v_rx] <span style=\"color: #AA22FF; font-weight: bold\">*</span> rxplaceholder_1[v_ff, v_rc, v_ry, v_rx]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">dense</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_matmul_NT: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;layout_free_buffers&quot;</span>: [<span style=\"color: #008000\">1</span>], <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NT&quot;</span>):\n",
       "                v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_i, v_k], rxplaceholder_1[v_j, v_k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NT[v_i, v_j])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    T_matmul_NT[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                T_matmul_NT[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NT[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> rxplaceholder_1[v_j, v_k]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">fused_dense_add0</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">900</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), w: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">900</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), b: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        R<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;Primitive&quot;</span>: <span style=\"color: #008000\">1</span>})\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(matmul, (x, w), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(add, (lv, b), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv1\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">fused_dense_add1</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), w: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), b: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        R<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;Primitive&quot;</span>: <span style=\"color: #008000\">1</span>})\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(dense, (x, w), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(add1, (lv1, b), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv2\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">matmul</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">900</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">900</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_matmul_NN: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;layout_free_buffers&quot;</span>: [<span style=\"color: #008000\">1</span>], <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">900</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NN&quot;</span>):\n",
       "                v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_i, v_k], rxplaceholder_1[v_k, v_j])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NN[v_i, v_j])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    T_matmul_NN[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                T_matmul_NN[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NN[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> rxplaceholder_1[v_k, v_j]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">relu</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), compute: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2, i3 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;compute&quot;</span>):\n",
       "                v_i0, v_i1, v_i2, v_i3 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSS&quot;</span>, [i0, i1, i2, i3])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_i0, v_i1, v_i2, v_i3])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(compute[v_i0, v_i1, v_i2, v_i3])\n",
       "                compute[v_i0, v_i1, v_i2, v_i3] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(rxplaceholder[v_i0, v_i1, v_i2, v_i3], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">relu1</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), compute: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;compute&quot;</span>):\n",
       "                v_i0, v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_i0, v_i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(compute[v_i0, v_i1])\n",
       "                compute[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(rxplaceholder[v_i0, v_i1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">reshape</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_reshape: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">900</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">900</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_reshape&quot;</span>):\n",
       "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>), v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">%</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">900</span>) <span style=\"color: #AA22FF; font-weight: bold\">//</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">%</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>)])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_reshape[v_ax0, v_ax1])\n",
       "                T_reshape[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> rxplaceholder[T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>), v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">%</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">900</span>) <span style=\"color: #AA22FF; font-weight: bold\">//</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">%</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>)]\n",
       "\n",
       "\n",
       "<span style=\"color: #007979; font-style: italic\"># Metadata omitted. Use show_meta=True in script() method to show it.</span>\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tvm import topi\n",
    "@relax.expr_functor.mutator\n",
    "class LowerToTensorIR(relax.PyExprMutator):\n",
    "    def __init__(self, mod: IRModule, op_map):\n",
    "        super().__init__()\n",
    "        self.mod_ = mod\n",
    "        self.op_map = {\n",
    "            tvm.ir.Op.get(k): v for k, v in op_map.items()\n",
    "        }\n",
    "        self.matmul_op = tvm.ir.Op.get('relax.matmul')\n",
    "    \n",
    "    def visit_call_(self, call: relax.Call):\n",
    "        call = self.visit_expr_post_order(call)\n",
    "\n",
    "        def match_call(node, op):\n",
    "            if not isinstance(node, relax.Call):\n",
    "                return False\n",
    "            return node.op == op\n",
    "        \n",
    "        if call.op in self.op_map:\n",
    "            call_pre = None\n",
    "            if match_call(call, self.matmul_op):\n",
    "                if isinstance(call.args[1], relax.expr.DataflowVar):\n",
    "                    call_pre = self.lookup_binding(call.args[1])\n",
    "            return self.op_map[call.op](self.builder_, call, call_pre)\n",
    "        # print(call.op, type(call.op), call.args)\n",
    "        return call\n",
    "\n",
    "    def transform(self):\n",
    "        for global_var, func in self.mod_.functions.items():\n",
    "            if not isinstance(func, relax.Function):\n",
    "                continue\n",
    "            updated_fn = self.visit_expr(func)\n",
    "            updated_fn = relax.analysis.remove_all_unused(updated_fn)\n",
    "            self.builder_.update_func(global_var, updated_fn)\n",
    "\n",
    "        return self.builder_.get()\n",
    "\n",
    "# def map_attrs(n):\n",
    "#     return (x.numpy() for x in n)\n",
    "\n",
    "def map_add(bb: relax.BlockBuilder, call, call_pre=None):\n",
    "    x, b = call.args\n",
    "    return bb.call_te(topi.add, x, b)\n",
    "\n",
    "def map_matmul(bb: relax.BlockBuilder, call, call_pre=None):\n",
    "    x, w = call.args\n",
    "    if call_pre and call_pre.op == tvm.ir.Op.get('relax.permute_dims'):\n",
    "        w = call_pre.args[0]\n",
    "        return bb.call_te(topi.nn.dense, x, w)\n",
    "    return bb.call_te(topi.nn.matmul, x, w)\n",
    "\n",
    "def map_relu(bb: relax.BlockBuilder, call, call_pre=None):\n",
    "    x = call.args[0]\n",
    "    return bb.call_te(topi.nn.relu, x)\n",
    "\n",
    "def map_conv(bb: relax.BlockBuilder, call: relax.Call, call_pre=None):\n",
    "    x, k = call.args\n",
    "    attrs = call.attrs\n",
    "\n",
    "    return bb.call_te(topi.nn.conv2d, x, k, attrs.strides, attrs.padding, attrs.dilation)\n",
    "\n",
    "def map_reshape(bb: relax.BlockBuilder, call: relax.Call, call_pre=None):\n",
    "    x, shape = call.args\n",
    "    return bb.call_te(topi.reshape, x, shape)\n",
    "\n",
    "op_map = {\n",
    "    'relax.matmul': map_matmul,\n",
    "    'relax.add': map_add,\n",
    "    'relax.nn.relu': map_relu,\n",
    "    'relax.nn.conv2d': map_conv,\n",
    "    'relax.reshape': map_reshape\n",
    "}\n",
    "\n",
    "@tvm.ir.transform.module_pass(opt_level=0, name=\"LowerToTensorIR\")\n",
    "class LowerToTensorIRPass:\n",
    "    \"\"\"The wrapper for the LowerTensorIR pass.\"\"\"\n",
    "    def transform_module(self, mod, ctx):\n",
    "        return LowerToTensorIR(mod, op_map).transform()\n",
    "\n",
    "\n",
    "DemoModelTIR = LowerToTensorIRPass()(DemoFused)\n",
    "# DemoModelTIR.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relax.op.nn.conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 融合R.function 与 T.prim_func\n",
    "DemoModelFinal = relax.transform.FuseTIR()(DemoModelTIR)\n",
    "# DemoModelFinal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-13 23:04:24 [INFO] [task_scheduler.cc:260] Task #0 has finished. Remaining task(s): 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>main</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>2.9171</td>\n",
       "      <td>2.9171</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name    FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0   main       1         1            0.0003          2.9171    \n",
       "\n",
       "    Weighted Latency (us)    Trials    Done   \n",
       "0                  2.9171         1       Y   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-13 23:04:24 [DEBUG] [task_scheduler.cc:318] \n",
      " ID | Name | FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "---------------------------------------------------------------------------------------------------\n",
      "  0 | main |    1 |      1 |         0.0003 |       2.9171 |                2.9171 |      1 |    Y \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total trials: 1\n",
      "Total latency (us): 2.91708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from MLC import mlc\n",
    "mod_tn = mlc.mlc_tune_tir(DemoModelFinal,target=\"cuda --max_threads_per_block=1024 --max_shared_memory_per_block=49152\",\n",
    "                           work_dir=\"./tune_tmp/\",\n",
    "                            task_name='main',\n",
    "                            max_trials_global=1,\n",
    "                            num_trials_per_iter=1, compile_tir_target='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod_tn.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 算子优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModuleWithParams2 time-cost: 0.307037 ms\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(1, 1, hw, hw).astype('float32')\n",
    "x_nd_cpu = tvm.nd.array(x)\n",
    "x_nd_cuda = tvm.nd.array(x, tvm.cuda(0))\n",
    "DemoModelFinal_ = DemoModelFinal\n",
    "ex_cpu = relax.vm.build(DemoModelFinal_, target='llvm')\n",
    "vm_cpu = relax.VirtualMachine(ex_cpu, tvm.cpu(0))\n",
    "\n",
    "f_timer_cpu = vm_cpu.time_evaluator('main', tvm.cpu(0), number=nrepeat)\n",
    "\n",
    "print(\"MyModuleWithParams2 time-cost: %g ms\" % (f_timer_cpu(x_nd_cpu).mean * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API只支持一个main的IRModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['relu1', 'fused_dense_add1', 'conv2d', 'fused_dense_add0', 'relu', 'reshape']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in DemoModelFinal.functions:\n",
    "#     print(i.name_hint)\n",
    "\n",
    "fn_names = [x.name_hint for x in DemoModelFinal.functions]\n",
    "fn_names.remove('main')\n",
    "fn_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-13 23:01:23 [INFO] [task_scheduler.cc:260] Task #0 has finished. Remaining task(s): 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>main</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>3.1002</td>\n",
       "      <td>3.1002</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name    FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0   main       1         1            0.0003          3.1002    \n",
       "\n",
       "    Weighted Latency (us)    Trials    Done   \n",
       "0                  3.1002         1       Y   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-13 23:01:23 [DEBUG] [task_scheduler.cc:318] \n",
      " ID | Name | FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "---------------------------------------------------------------------------------------------------\n",
      "  0 | main |    1 |      1 |         0.0003 |       3.1002 |                3.1002 |      1 |    Y \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total trials: 1\n",
      "Total latency (us): 3.10024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tvm import meta_schedule as ms\n",
    "\n",
    "for fn_name in fn_names:\n",
    "    print(fn_name)\n",
    "    mod_ = tvm.IRModule.from_expr(DemoModelFinal[fn_name].with_attr(\"global_symbol\", 'main'))\n",
    "\n",
    "\n",
    "    tuned_record = ms.tune_tir(mod_, target=\"cuda --max_threads_per_block=1024 --max_shared_memory_per_block=49152\",\n",
    "                           work_dir=\"./tune_tmp/\",\n",
    "                            task_name='main',\n",
    "                            max_trials_global=1,\n",
    "                            num_trials_per_iter=1)\n",
    "    \n",
    "    tuned_sch = ms.tir_integration.compile_tir(tuned_record, mod_, target='cuda')\n",
    "    new_func = tuned_sch.mod['main'].with_attr(\"global_symbol\", fn_name)\n",
    "    gv = DemoModelFinal.get_global_var(fn_name)\n",
    "    DemoModelFinal.update_func(gv, new_func)\n",
    "    # break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/staff/qiaoliang/anaconda3/envs/MLC/lib/python3.8/site-packages/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
      "To print formatted TVM script, please install the formatter 'Black':\n",
      "/staff/qiaoliang/anaconda3/envs/MLC/bin/python -m pip install \"black==22.3.0\" --upgrade --user\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">32</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(conv2d, (x, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">30</span>, <span style=\"color: #008000\">30</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(relu, (lv,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">30</span>, <span style=\"color: #008000\">30</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(reshape, (lv1,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">900</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv4 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(fused_dense_add0, (lv2, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">1</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">2</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv5 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(relu1, (lv4,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv8 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(fused_dense_add1, (lv5, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">3</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">4</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv8\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">conv2d</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), conv2d_nchw: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;conv2d&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        conv2d_nchw_local <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>)), scope<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;local&quot;</span>)\n",
       "        pad_temp_shared <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>)), scope<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;shared&quot;</span>)\n",
       "        rxplaceholder_shared <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>)), scope<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;shared&quot;</span>)\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> nn_0_ff_0_yy_0_xx_0_fused <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>thread_binding(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), thread<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;blockIdx.x&quot;</span>, annotations<span style=\"color: #AA22FF; font-weight: bold\">=</span>{<span style=\"color: #BA2121\">&quot;pragma_auto_unroll_max_step&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">512</span>), <span style=\"color: #BA2121\">&quot;pragma_unroll_explicit&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>)}):\n",
       "            <span style=\"color: #008000; font-weight: bold\">for</span> nn_1_ff_1_yy_1_xx_1_fused <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>thread_binding(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), thread<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;vthread.x&quot;</span>):\n",
       "                <span style=\"color: #008000; font-weight: bold\">for</span> nn_2_ff_2_yy_2_xx_2_fused <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>thread_binding(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">60</span>), thread<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;threadIdx.x&quot;</span>):\n",
       "                    <span style=\"color: #008000; font-weight: bold\">for</span> nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">5</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>)):\n",
       "                        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;conv2d_nchw_init&quot;</span>):\n",
       "                            v_nn <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), nn_3_init <span style=\"color: #AA22FF; font-weight: bold\">+</span> nn_4_init)\n",
       "                            v_ff <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), ff_4_init <span style=\"color: #AA22FF; font-weight: bold\">+</span> ff_3_init)\n",
       "                            v_yy <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), nn_0_ff_0_yy_0_xx_0_fused <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> nn_2_ff_2_yy_2_xx_2_fused <span style=\"color: #AA22FF; font-weight: bold\">//</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>) <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">5</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> yy_3_init <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">5</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> yy_4_init)\n",
       "                            v_xx <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), xx_3_init <span style=\"color: #AA22FF; font-weight: bold\">+</span> xx_4_init <span style=\"color: #AA22FF; font-weight: bold\">+</span> nn_2_ff_2_yy_2_xx_2_fused <span style=\"color: #AA22FF; font-weight: bold\">%</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>))\n",
       "                            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads()\n",
       "                            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx])\n",
       "                            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block_attr({<span style=\"color: #BA2121\">&quot;meta_schedule.thread_extent_high_inclusive&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1024</span>), <span style=\"color: #BA2121\">&quot;meta_schedule.thread_extent_low_inclusive&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), <span style=\"color: #BA2121\">&quot;meta_schedule.tiling_structure&quot;</span>: <span style=\"color: #BA2121\">&quot;SSSRRSRS&quot;</span>})\n",
       "                            conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                    <span style=\"color: #008000; font-weight: bold\">for</span> rc_0, ry_0, rx_0 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>)):\n",
       "                        <span style=\"color: #008000; font-weight: bold\">for</span> ax0_ax1_ax2_ax3_fused_0 <span style=\"color: #008000; font-weight: bold\">in</span> range(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">4</span>)):\n",
       "                            <span style=\"color: #008000; font-weight: bold\">for</span> ax0_ax1_ax2_ax3_fused_1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>thread_binding(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">60</span>), thread<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;threadIdx.x&quot;</span>):\n",
       "                                <span style=\"color: #008000; font-weight: bold\">for</span> ax0_ax1_ax2_ax3_fused_2 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>vectorized(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>)):\n",
       "                                    <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;pad_temp_shared&quot;</span>):\n",
       "                                        v0 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>))\n",
       "                                        v1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>))\n",
       "                                        v2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), nn_0_ff_0_yy_0_xx_0_fused <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> (ax0_ax1_ax2_ax3_fused_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">120</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax0_ax1_ax2_ax3_fused_1 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax0_ax1_ax2_ax3_fused_2) <span style=\"color: #AA22FF; font-weight: bold\">//</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>))\n",
       "                                        v3 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), (ax0_ax1_ax2_ax3_fused_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">120</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax0_ax1_ax2_ax3_fused_1 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax0_ax1_ax2_ax3_fused_2) <span style=\"color: #AA22FF; font-weight: bold\">%</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>))\n",
       "                                        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>where((ax0_ax1_ax2_ax3_fused_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">60</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax0_ax1_ax2_ax3_fused_1) <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax0_ax1_ax2_ax3_fused_2 <span style=\"color: #AA22FF; font-weight: bold\">&lt;</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">384</span>))\n",
       "                                        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v0, v1, v2, v3])\n",
       "                                        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(pad_temp_shared[v0, v1, v2, v3])\n",
       "                                        pad_temp_shared[v0, v1, v2, v3] <span style=\"color: #AA22FF; font-weight: bold\">=</span> rxplaceholder[v0, v1, v2, v3]\n",
       "                        <span style=\"color: #008000; font-weight: bold\">for</span> ax0_ax1_ax2_ax3_fused_0 <span style=\"color: #008000; font-weight: bold\">in</span> range(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>)):\n",
       "                            <span style=\"color: #008000; font-weight: bold\">for</span> ax0_ax1_ax2_ax3_fused_1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>thread_binding(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">60</span>), thread<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;threadIdx.x&quot;</span>):\n",
       "                                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;rxplaceholder_shared&quot;</span>):\n",
       "                                    v0 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>))\n",
       "                                    v1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>))\n",
       "                                    v2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), (ax0_ax1_ax2_ax3_fused_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">60</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax0_ax1_ax2_ax3_fused_1) <span style=\"color: #AA22FF; font-weight: bold\">//</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>))\n",
       "                                    v3 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), (ax0_ax1_ax2_ax3_fused_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">60</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax0_ax1_ax2_ax3_fused_1) <span style=\"color: #AA22FF; font-weight: bold\">%</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>))\n",
       "                                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>where(ax0_ax1_ax2_ax3_fused_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">60</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax0_ax1_ax2_ax3_fused_1 <span style=\"color: #AA22FF; font-weight: bold\">&lt;</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">9</span>))\n",
       "                                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder_1[v0, v1, v2, v3])\n",
       "                                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(rxplaceholder_shared[v0, v1, v2, v3])\n",
       "                                    rxplaceholder_shared[v0, v1, v2, v3] <span style=\"color: #AA22FF; font-weight: bold\">=</span> rxplaceholder_1[v0, v1, v2, v3]\n",
       "                        <span style=\"color: #008000; font-weight: bold\">for</span> rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">5</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>)):\n",
       "                            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;conv2d_nchw_update&quot;</span>):\n",
       "                                v_nn <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), nn_3 <span style=\"color: #AA22FF; font-weight: bold\">+</span> nn_4)\n",
       "                                v_ff <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), ff_4 <span style=\"color: #AA22FF; font-weight: bold\">+</span> ff_3)\n",
       "                                v_yy <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), nn_0_ff_0_yy_0_xx_0_fused <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> nn_2_ff_2_yy_2_xx_2_fused <span style=\"color: #AA22FF; font-weight: bold\">//</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>) <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">5</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> yy_3 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">5</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> yy_4)\n",
       "                                v_xx <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), xx_3 <span style=\"color: #AA22FF; font-weight: bold\">+</span> xx_4 <span style=\"color: #AA22FF; font-weight: bold\">+</span> nn_2_ff_2_yy_2_xx_2_fused <span style=\"color: #AA22FF; font-weight: bold\">%</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>))\n",
       "                                v_rc <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>reduce(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), rc_0 <span style=\"color: #AA22FF; font-weight: bold\">+</span> rc_1 <span style=\"color: #AA22FF; font-weight: bold\">+</span> rc_2)\n",
       "                                v_ry <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>reduce(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), ry_2 <span style=\"color: #AA22FF; font-weight: bold\">+</span> ry_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ry_1)\n",
       "                                v_rx <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>reduce(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), rx_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> rx_1 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> rx_2)\n",
       "                                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy <span style=\"color: #AA22FF; font-weight: bold\">+</span> v_ry, v_xx <span style=\"color: #AA22FF; font-weight: bold\">+</span> v_rx], rxplaceholder_shared[v_ff, v_rc, v_ry, v_rx])\n",
       "                                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx])\n",
       "                                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block_attr({<span style=\"color: #BA2121\">&quot;meta_schedule.thread_extent_high_inclusive&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1024</span>), <span style=\"color: #BA2121\">&quot;meta_schedule.thread_extent_low_inclusive&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), <span style=\"color: #BA2121\">&quot;meta_schedule.tiling_structure&quot;</span>: <span style=\"color: #BA2121\">&quot;SSSRRSRS&quot;</span>})\n",
       "                                conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] <span style=\"color: #AA22FF; font-weight: bold\">=</span> conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] <span style=\"color: #AA22FF; font-weight: bold\">+</span> pad_temp_shared[v_nn, v_rc, v_yy <span style=\"color: #AA22FF; font-weight: bold\">+</span> v_ry, v_xx <span style=\"color: #AA22FF; font-weight: bold\">+</span> v_rx] <span style=\"color: #AA22FF; font-weight: bold\">*</span> rxplaceholder_shared[v_ff, v_rc, v_ry, v_rx]\n",
       "                    <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1, ax2, ax3 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">5</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>)):\n",
       "                        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;conv2d_nchw_local&quot;</span>):\n",
       "                            v0, v1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                            v2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), nn_0_ff_0_yy_0_xx_0_fused <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> nn_2_ff_2_yy_2_xx_2_fused <span style=\"color: #AA22FF; font-weight: bold\">//</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>) <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">5</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax2)\n",
       "                            v3 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), nn_2_ff_2_yy_2_xx_2_fused <span style=\"color: #AA22FF; font-weight: bold\">%</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax3)\n",
       "                            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(conv2d_nchw_local[v0, v1, v2, v3])\n",
       "                            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(conv2d_nchw[v0, v1, v2, v3])\n",
       "                            conv2d_nchw[v0, v1, v2, v3] <span style=\"color: #AA22FF; font-weight: bold\">=</span> conv2d_nchw_local[v0, v1, v2, v3]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">fused_dense_add0</span>(x: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">900</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), w: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">900</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), b: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>),), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_add: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;fused_dense_add0&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        T_matmul_NN_local <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), scope<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;local&quot;</span>)\n",
       "        x_shared <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">900</span>)), scope<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;shared&quot;</span>)\n",
       "        w_shared <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">900</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), scope<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;shared&quot;</span>)\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i_0_j_0_fused <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>thread_binding(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">4</span>), thread<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;blockIdx.x&quot;</span>, annotations<span style=\"color: #AA22FF; font-weight: bold\">=</span>{<span style=\"color: #BA2121\">&quot;pragma_auto_unroll_max_step&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1024</span>), <span style=\"color: #BA2121\">&quot;pragma_unroll_explicit&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>)}):\n",
       "            <span style=\"color: #008000; font-weight: bold\">for</span> i_1_j_1_fused <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>thread_binding(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), thread<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;vthread.x&quot;</span>):\n",
       "                <span style=\"color: #008000; font-weight: bold\">for</span> i_2_j_2_fused <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>thread_binding(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), thread<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;threadIdx.x&quot;</span>):\n",
       "                    <span style=\"color: #008000; font-weight: bold\">for</span> i_3_init, j_3_init, i_4_init, j_4_init <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>)):\n",
       "                        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NN_init&quot;</span>):\n",
       "                            v_i <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), i_4_init <span style=\"color: #AA22FF; font-weight: bold\">+</span> i_3_init)\n",
       "                            v_j <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), j_4_init <span style=\"color: #AA22FF; font-weight: bold\">+</span> i_0_j_0_fused <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> i_2_j_2_fused <span style=\"color: #AA22FF; font-weight: bold\">+</span> j_3_init)\n",
       "                            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads()\n",
       "                            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NN_local[v_i, v_j])\n",
       "                            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block_attr({<span style=\"color: #BA2121\">&quot;meta_schedule.thread_extent_high_inclusive&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1024</span>), <span style=\"color: #BA2121\">&quot;meta_schedule.thread_extent_low_inclusive&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), <span style=\"color: #BA2121\">&quot;meta_schedule.tiling_structure&quot;</span>: <span style=\"color: #BA2121\">&quot;SSSRRSRS&quot;</span>})\n",
       "                            T_matmul_NN_local[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                    <span style=\"color: #008000; font-weight: bold\">for</span> k_0 <span style=\"color: #008000; font-weight: bold\">in</span> range(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">5</span>)):\n",
       "                        <span style=\"color: #008000; font-weight: bold\">for</span> ax0_ax1_fused_0 <span style=\"color: #008000; font-weight: bold\">in</span> range(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>)):\n",
       "                            <span style=\"color: #008000; font-weight: bold\">for</span> ax0_ax1_fused_1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>thread_binding(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), thread<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;threadIdx.x&quot;</span>):\n",
       "                                <span style=\"color: #008000; font-weight: bold\">for</span> ax0_ax1_fused_2 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>vectorized(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>)):\n",
       "                                    <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;x_shared&quot;</span>):\n",
       "                                        v0 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>))\n",
       "                                        v1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">900</span>), k_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">180</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> (ax0_ax1_fused_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">96</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax0_ax1_fused_1 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax0_ax1_fused_2))\n",
       "                                        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>where((ax0_ax1_fused_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax0_ax1_fused_1) <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax0_ax1_fused_2 <span style=\"color: #AA22FF; font-weight: bold\">&lt;</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">180</span>))\n",
       "                                        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(x[v0, v1])\n",
       "                                        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(x_shared[v0, v1])\n",
       "                                        x_shared[v0, v1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> x[v0, v1]\n",
       "                        <span style=\"color: #008000; font-weight: bold\">for</span> ax0_ax1_fused_0 <span style=\"color: #008000; font-weight: bold\">in</span> range(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">90</span>)):\n",
       "                            <span style=\"color: #008000; font-weight: bold\">for</span> ax0_ax1_fused_1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>thread_binding(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), thread<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;threadIdx.x&quot;</span>):\n",
       "                                <span style=\"color: #008000; font-weight: bold\">for</span> ax0_ax1_fused_2 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>vectorized(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>)):\n",
       "                                    <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;w_shared&quot;</span>):\n",
       "                                        v0 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">900</span>), k_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">180</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> (ax0_ax1_fused_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax0_ax1_fused_1 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax0_ax1_fused_2) <span style=\"color: #AA22FF; font-weight: bold\">//</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>))\n",
       "                                        v1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), i_0_j_0_fused <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> (ax0_ax1_fused_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax0_ax1_fused_1 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax0_ax1_fused_2) <span style=\"color: #AA22FF; font-weight: bold\">%</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>))\n",
       "                                        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(w[v0, v1])\n",
       "                                        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(w_shared[v0, v1])\n",
       "                                        w_shared[v0, v1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> w[v0, v1]\n",
       "                        <span style=\"color: #008000; font-weight: bold\">for</span> k_1, i_3, j_3, k_2, i_4, j_4 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">180</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>)):\n",
       "                            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NN_update&quot;</span>):\n",
       "                                v_i <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), i_4 <span style=\"color: #AA22FF; font-weight: bold\">+</span> i_3)\n",
       "                                v_j <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), j_4 <span style=\"color: #AA22FF; font-weight: bold\">+</span> i_0_j_0_fused <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> i_2_j_2_fused <span style=\"color: #AA22FF; font-weight: bold\">+</span> j_3)\n",
       "                                v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>reduce(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">900</span>), k_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">180</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> k_1 <span style=\"color: #AA22FF; font-weight: bold\">+</span> k_2)\n",
       "                                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(T_matmul_NN_local[v_i, v_j], x_shared[v_i, v_k], w_shared[v_k, v_j])\n",
       "                                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NN_local[v_i, v_j])\n",
       "                                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block_attr({<span style=\"color: #BA2121\">&quot;meta_schedule.thread_extent_high_inclusive&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1024</span>), <span style=\"color: #BA2121\">&quot;meta_schedule.thread_extent_low_inclusive&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), <span style=\"color: #BA2121\">&quot;meta_schedule.tiling_structure&quot;</span>: <span style=\"color: #BA2121\">&quot;SSSRRSRS&quot;</span>})\n",
       "                                T_matmul_NN_local[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NN_local[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> x_shared[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> w_shared[v_k, v_j]\n",
       "                    <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>)):\n",
       "                        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NN_local&quot;</span>):\n",
       "                            v0 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), ax0)\n",
       "                            v1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), i_0_j_0_fused <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> i_2_j_2_fused <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax1)\n",
       "                            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(T_matmul_NN_local[v0, v1], b[v1])\n",
       "                            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_add[v0, v1])\n",
       "                            T_add[v0, v1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NN_local[v0, v1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> b[v1]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">fused_dense_add1</span>(x: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), w: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), b: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>),), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_add: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;fused_dense_add1&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        T_matmul_NT <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)))\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i_0 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>serial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), annotations<span style=\"color: #AA22FF; font-weight: bold\">=</span>{<span style=\"color: #BA2121\">&quot;pragma_auto_unroll_max_step&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>), <span style=\"color: #BA2121\">&quot;pragma_unroll_explicit&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>)}):\n",
       "            <span style=\"color: #008000; font-weight: bold\">for</span> j_0, i_1, j_1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>)):\n",
       "                <span style=\"color: #008000; font-weight: bold\">for</span> i_2_init, j_2_init, i_3_init <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">5</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>)):\n",
       "                    <span style=\"color: #008000; font-weight: bold\">for</span> j_3_fused_init <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>vectorized(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>)):\n",
       "                        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NT_init&quot;</span>):\n",
       "                            v_i <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), i_0 <span style=\"color: #AA22FF; font-weight: bold\">+</span> i_1 <span style=\"color: #AA22FF; font-weight: bold\">+</span> i_2_init <span style=\"color: #AA22FF; font-weight: bold\">+</span> i_3_init)\n",
       "                            v_j <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), j_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> j_1 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> j_2_init <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> j_3_fused_init)\n",
       "                            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads()\n",
       "                            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NT[v_i, v_j])\n",
       "                            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block_attr({<span style=\"color: #BA2121\">&quot;meta_schedule.tiling_structure&quot;</span>: <span style=\"color: #BA2121\">&quot;SSRSRS&quot;</span>})\n",
       "                            T_matmul_NT[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                <span style=\"color: #008000; font-weight: bold\">for</span> k_0, i_2, j_2, k_1, i_3 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">16</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">5</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">8</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>)):\n",
       "                    <span style=\"color: #008000; font-weight: bold\">for</span> j_3_fused <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>vectorized(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>)):\n",
       "                        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NT_update&quot;</span>):\n",
       "                            v_i <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), i_0 <span style=\"color: #AA22FF; font-weight: bold\">+</span> i_1 <span style=\"color: #AA22FF; font-weight: bold\">+</span> i_2 <span style=\"color: #AA22FF; font-weight: bold\">+</span> i_3)\n",
       "                            v_j <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), j_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> j_1 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> j_2 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> j_3_fused)\n",
       "                            v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>reduce(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), k_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">8</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> k_1)\n",
       "                            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(T_matmul_NT[v_i, v_j], x[v_i, v_k], w[v_j, v_k])\n",
       "                            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NT[v_i, v_j])\n",
       "                            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block_attr({<span style=\"color: #BA2121\">&quot;meta_schedule.tiling_structure&quot;</span>: <span style=\"color: #BA2121\">&quot;SSRSRS&quot;</span>})\n",
       "                            T_matmul_NT[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NT[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> x[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> w[v_j, v_k]\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0_ax1_fused <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>vectorized(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), annotations<span style=\"color: #AA22FF; font-weight: bold\">=</span>{<span style=\"color: #BA2121\">&quot;pragma_auto_unroll_max_step&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>), <span style=\"color: #BA2121\">&quot;pragma_unroll_explicit&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>)}):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
       "                v_ax0 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>))\n",
       "                v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), ax0_ax1_fused)\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(T_matmul_NT[v_ax0, v_ax1], b[v_ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_add[v_ax0, v_ax1])\n",
       "                T_add[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NT[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> b[v_ax1]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">relu</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), compute: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;relu&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0_i1_i2_i3_fused_0 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>thread_binding(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>), thread<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;blockIdx.x&quot;</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">for</span> i0_i1_i2_i3_fused_1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>thread_binding(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">512</span>), thread<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;threadIdx.x&quot;</span>):\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;compute&quot;</span>):\n",
       "                    v_i0 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>))\n",
       "                    v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>))\n",
       "                    v_i2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), (i0_i1_i2_i3_fused_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">512</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> i0_i1_i2_i3_fused_1) <span style=\"color: #AA22FF; font-weight: bold\">//</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>))\n",
       "                    v_i3 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), (i0_i1_i2_i3_fused_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">512</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> i0_i1_i2_i3_fused_1) <span style=\"color: #AA22FF; font-weight: bold\">%</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>))\n",
       "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>where(i0_i1_i2_i3_fused_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">512</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> i0_i1_i2_i3_fused_1 <span style=\"color: #AA22FF; font-weight: bold\">&lt;</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">900</span>))\n",
       "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_i0, v_i1, v_i2, v_i3])\n",
       "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(compute[v_i0, v_i1, v_i2, v_i3])\n",
       "                    compute[v_i0, v_i1, v_i2, v_i3] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(rxplaceholder[v_i0, v_i1, v_i2, v_i3], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">relu1</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), compute: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;relu1&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0_i1_fused_0 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>thread_binding(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">4</span>), thread<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;blockIdx.x&quot;</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">for</span> i0_i1_fused_1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>thread_binding(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), thread<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;threadIdx.x&quot;</span>):\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;compute&quot;</span>):\n",
       "                    v_i0 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>))\n",
       "                    v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), i0_i1_fused_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> i0_i1_fused_1)\n",
       "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_i0, v_i1])\n",
       "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(compute[v_i0, v_i1])\n",
       "                    compute[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(rxplaceholder[v_i0, v_i1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">reshape</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_reshape: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">900</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;reshape&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0_ax1_fused_0 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>thread_binding(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">29</span>), thread<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;blockIdx.x&quot;</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">for</span> ax0_ax1_fused_1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>thread_binding(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), thread<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;threadIdx.x&quot;</span>):\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_reshape&quot;</span>):\n",
       "                    v_ax0 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>))\n",
       "                    v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">900</span>), ax0_ax1_fused_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax0_ax1_fused_1)\n",
       "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>where(ax0_ax1_fused_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>) <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax0_ax1_fused_1 <span style=\"color: #AA22FF; font-weight: bold\">&lt;</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">900</span>))\n",
       "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>), v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">%</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">900</span>) <span style=\"color: #AA22FF; font-weight: bold\">//</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">%</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>)])\n",
       "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_reshape[v_ax0, v_ax1])\n",
       "                    T_reshape[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> rxplaceholder[T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>), v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">%</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">900</span>) <span style=\"color: #AA22FF; font-weight: bold\">//</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">%</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>)]\n",
       "\n",
       "\n",
       "<span style=\"color: #007979; font-style: italic\"># Metadata omitted. Use show_meta=True in script() method to show it.</span>\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DemoModelFinal_cuda = DemoModelFinal_\n",
    "DemoModelFinal_cuda.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo in cuda time-cost: 0.023727 ms\n"
     ]
    }
   ],
   "source": [
    "ex_cuda = relax.vm.build(DemoModelFinal_cuda, target='cuda')\n",
    "vm_cuda = relax.VirtualMachine(ex_cuda, tvm.cuda(0))\n",
    "\n",
    "\n",
    "f_timer_cuda = vm_cuda.time_evaluator('main', tvm.cuda(0), number=nrepeat)\n",
    "\n",
    "print(\"Demo in cuda time-cost: %g ms\" % (f_timer_cuda(x_nd_cuda).mean * 1000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo\n",
    "torch 0.34713 -> cpu 0.262574 ms -> auto tune 0.0233462 ms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df7b789d6764113f3eb4ff8e192e7912fbf893c46539f75332048503ce5ba603"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
